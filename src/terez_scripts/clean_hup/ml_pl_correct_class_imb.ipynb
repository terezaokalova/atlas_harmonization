{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [code]\n",
    "\"\"\"\n",
    "ML Pipeline with Class Imbalance Correction\n",
    "\n",
    "This script:\n",
    "1. Loads aggregated data from all subjects.\n",
    "2. One-hot encodes the ROI information from the 'roiNum' column.\n",
    "3. Defines an explicit feature list (bandpower, FOOOF, entropy, catch22, and ROI dummies).\n",
    "4. Splits the data at the subject level.\n",
    "5. Standardizes features.\n",
    "6. Trains models (Random Forest, Logistic Regression, SVM, and XGBoost) using group-aware CV,\n",
    "   setting class_weight='balanced' (or scale_pos_weight for XGBoost) to correct for class imbalance.\n",
    "7. Evaluates models on a held-out test set and prints detailed performance metrics.\n",
    "\n",
    "Requirements:\n",
    "    pip install numpy pandas scikit-learn matplotlib pycatch22 xgboost\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pycatch22\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GroupKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    roc_auc_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    ConfusionMatrixDisplay\n",
    ")\n",
    "from sklearn.inspection import permutation_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from all subjects...\n",
      "Combined data shape: (1675, 51)\n",
      "ROI one-hot encoding completed.\n",
      "Using explicit feature list with 118 features.\n",
      "Total unique subjects: 23\n",
      "Training subjects: ['sub-RID0179' 'sub-RID0032' 'sub-RID0238' 'sub-RID0064' 'sub-RID0033'\n",
      " 'sub-RID0175' 'sub-RID0562' 'sub-RID0050' 'sub-RID0051' 'sub-RID0424'\n",
      " 'sub-RID0381' 'sub-RID0589' 'sub-RID0658' 'sub-RID0101' 'sub-RID0167'\n",
      " 'sub-RID0301' 'sub-RID0508' 'sub-RID0089']\n",
      "Testing subjects: ['sub-RID0320' 'sub-RID0143' 'sub-RID0031' 'sub-RID0117' 'sub-RID0405']\n",
      "Training set shape: (1251, 118)\n",
      "Test set shape: (424, 118)\n",
      "\n",
      "=======================================\n",
      "Training Model: RANDOM_FOREST\n",
      "\n",
      "=== RANDOM_FOREST GROUP-CV Results ===\n",
      "Accuracy: 0.857 ± 0.054\n",
      "ROC AUC: 0.579 ± 0.127\n",
      "\n",
      "--- RANDOM_FOREST TEST SET PERFORMANCE ---\n",
      "Accuracy: 0.8349056603773585\n",
      "ROC AUC: 0.6467701392490922\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      1.00      0.91       353\n",
      "           1       1.00      0.01      0.03        71\n",
      "\n",
      "    accuracy                           0.83       424\n",
      "   macro avg       0.92      0.51      0.47       424\n",
      "weighted avg       0.86      0.83      0.76       424\n",
      "\n",
      "Confusion Matrix:\n",
      "[[353   0]\n",
      " [ 70   1]]\n",
      "\n",
      "=======================================\n",
      "Training Model: LOGISTIC\n",
      "\n",
      "=== LOGISTIC GROUP-CV Results ===\n",
      "Accuracy: 0.772 ± 0.023\n",
      "ROC AUC: 0.650 ± 0.103\n",
      "\n",
      "--- LOGISTIC TEST SET PERFORMANCE ---\n",
      "Accuracy: 0.7240566037735849\n",
      "ROC AUC: 0.7309579858755935\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.77      0.82       353\n",
      "           1       0.30      0.48      0.37        71\n",
      "\n",
      "    accuracy                           0.72       424\n",
      "   macro avg       0.59      0.63      0.60       424\n",
      "weighted avg       0.78      0.72      0.75       424\n",
      "\n",
      "Confusion Matrix:\n",
      "[[273  80]\n",
      " [ 37  34]]\n",
      "\n",
      "=======================================\n",
      "Training Model: SVM\n",
      "\n",
      "=== SVM GROUP-CV Results ===\n",
      "Accuracy: 0.771 ± 0.033\n",
      "ROC AUC: 0.607 ± 0.116\n",
      "\n",
      "--- SVM TEST SET PERFORMANCE ---\n",
      "Accuracy: 0.7169811320754716\n",
      "ROC AUC: 0.6938913936879065\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.78      0.82       353\n",
      "           1       0.27      0.39      0.32        71\n",
      "\n",
      "    accuracy                           0.72       424\n",
      "   macro avg       0.57      0.59      0.57       424\n",
      "weighted avg       0.76      0.72      0.74       424\n",
      "\n",
      "Confusion Matrix:\n",
      "[[276  77]\n",
      " [ 43  28]]\n",
      "\n",
      "=======================================\n",
      "Training Model: XGBOOST\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tereza/anaconda3/envs/cnt_gen/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [15:43:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/tereza/anaconda3/envs/cnt_gen/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [15:43:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/tereza/anaconda3/envs/cnt_gen/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [15:43:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/tereza/anaconda3/envs/cnt_gen/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [15:43:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/tereza/anaconda3/envs/cnt_gen/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [15:43:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== XGBOOST GROUP-CV Results ===\n",
      "Accuracy: 0.834 ± 0.051\n",
      "ROC AUC: 0.614 ± 0.091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tereza/anaconda3/envs/cnt_gen/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [15:43:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- XGBOOST TEST SET PERFORMANCE ---\n",
      "Accuracy: 0.8042452830188679\n",
      "ROC AUC: 0.5937038662570323\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.93      0.89       353\n",
      "           1       0.32      0.15      0.21        71\n",
      "\n",
      "    accuracy                           0.80       424\n",
      "   macro avg       0.58      0.54      0.55       424\n",
      "weighted avg       0.76      0.80      0.77       424\n",
      "\n",
      "Confusion Matrix:\n",
      "[[330  23]\n",
      " [ 60  11]]\n",
      "\n",
      "=== Detailed Summary of All Model Results on Test Set ===\n",
      "\n",
      "------------------------------\n",
      "Model: RANDOM_FOREST\n",
      "Accuracy: 0.835\n",
      "ROC AUC: 0.6467701392490922\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      1.00      0.91       353\n",
      "           1       1.00      0.01      0.03        71\n",
      "\n",
      "    accuracy                           0.83       424\n",
      "   macro avg       0.92      0.51      0.47       424\n",
      "weighted avg       0.86      0.83      0.76       424\n",
      "\n",
      "Confusion Matrix:\n",
      "[[353   0]\n",
      " [ 70   1]]\n",
      "\n",
      "------------------------------\n",
      "Model: LOGISTIC\n",
      "Accuracy: 0.724\n",
      "ROC AUC: 0.7309579858755935\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.77      0.82       353\n",
      "           1       0.30      0.48      0.37        71\n",
      "\n",
      "    accuracy                           0.72       424\n",
      "   macro avg       0.59      0.63      0.60       424\n",
      "weighted avg       0.78      0.72      0.75       424\n",
      "\n",
      "Confusion Matrix:\n",
      "[[273  80]\n",
      " [ 37  34]]\n",
      "\n",
      "------------------------------\n",
      "Model: SVM\n",
      "Accuracy: 0.717\n",
      "ROC AUC: 0.6938913936879065\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.78      0.82       353\n",
      "           1       0.27      0.39      0.32        71\n",
      "\n",
      "    accuracy                           0.72       424\n",
      "   macro avg       0.57      0.59      0.57       424\n",
      "weighted avg       0.76      0.72      0.74       424\n",
      "\n",
      "Confusion Matrix:\n",
      "[[276  77]\n",
      " [ 43  28]]\n",
      "\n",
      "------------------------------\n",
      "Model: XGBOOST\n",
      "Accuracy: 0.804\n",
      "ROC AUC: 0.5937038662570323\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.93      0.89       353\n",
      "           1       0.32      0.15      0.21        71\n",
      "\n",
      "    accuracy                           0.80       424\n",
      "   macro avg       0.58      0.54      0.55       424\n",
      "weighted avg       0.76      0.80      0.77       424\n",
      "\n",
      "Confusion Matrix:\n",
      "[[330  23]\n",
      " [ 60  11]]\n"
     ]
    }
   ],
   "source": [
    "##################################\n",
    "# 1) DATA LOADING & MERGING\n",
    "##################################\n",
    "\n",
    "def convert_spared_to_label(val):\n",
    "    \"\"\"Convert 'spared' to binary: 0 if spared (TRUE), 1 if resected (FALSE).\"\"\"\n",
    "    if isinstance(val, bool):\n",
    "        return 0 if val else 1\n",
    "    elif isinstance(val, str):\n",
    "        return 0 if val.strip().upper() == 'TRUE' else 1\n",
    "    else:\n",
    "        return 0 if bool(val) else 1\n",
    "\n",
    "def load_all_subjects(subjects_dir, subject_list):\n",
    "    \"\"\"\n",
    "    Loads each subject's aggregated pickle file (e.g. sub-RIDXXXX_features_averaged.pkl),\n",
    "    adds a 'subject_id' column, converts 'spared' to a binary label, and concatenates all data.\n",
    "    \"\"\"\n",
    "    all_dfs = []\n",
    "    for subj in subject_list:\n",
    "        subj_path = os.path.join(subjects_dir, subj)\n",
    "        pkl_file = os.path.join(subj_path, f\"{subj}_features_averaged.pkl\")\n",
    "        if not os.path.isfile(pkl_file):\n",
    "            print(f\"Warning: file not found: {pkl_file}\")\n",
    "            continue\n",
    "        df = pd.read_pickle(pkl_file)\n",
    "        df['subject_id'] = subj\n",
    "        if 'spared' not in df.columns:\n",
    "            raise ValueError(f\"'spared' column missing for {subj}\")\n",
    "        df['label'] = df['spared'].apply(convert_spared_to_label)\n",
    "        all_dfs.append(df)\n",
    "    if not all_dfs:\n",
    "        raise ValueError(\"No data loaded. Check paths or subject list.\")\n",
    "    combined_df = pd.concat(all_dfs, axis=0, ignore_index=True)\n",
    "    return combined_df\n",
    "\n",
    "# Define subjects directory and list (adjust paths as needed)\n",
    "subjects_dir = \"/Users/tereza/nishant/atlas/atlas_work_terez/atlas_harmonization/Data/hup/derivatives/clean\"\n",
    "subject_list = [\n",
    "    \"sub-RID0031\", \"sub-RID0032\", \"sub-RID0033\", \"sub-RID0050\", \"sub-RID0051\", \n",
    "    \"sub-RID0064\", \"sub-RID0089\", \"sub-RID0101\", \"sub-RID0117\", \"sub-RID0143\",\n",
    "    \"sub-RID0167\", \"sub-RID0175\", \"sub-RID0179\", \"sub-RID0238\", \"sub-RID0301\",\n",
    "    \"sub-RID0320\", \"sub-RID0381\", \"sub-RID0405\", \"sub-RID0424\", \"sub-RID0508\",\n",
    "    \"sub-RID0562\", \"sub-RID0589\", \"sub-RID0658\"\n",
    "]\n",
    "\n",
    "print(\"Loading data from all subjects...\")\n",
    "combined_df = load_all_subjects(subjects_dir, subject_list)\n",
    "print(f\"Combined data shape: {combined_df.shape}\")\n",
    "\n",
    "##################################\n",
    "# 2) INCLUDE ROI AS A FEATURE\n",
    "##################################\n",
    "# We assume the ROI identifier is stored in 'roiNum'\n",
    "# Convert 'roiNum' to a categorical variable (as string) and one-hot encode it.\n",
    "combined_df['roiNum_cat'] = combined_df['roiNum'].astype(str)\n",
    "roi_dummies = pd.get_dummies(combined_df['roiNum_cat'], prefix='roiNum')\n",
    "combined_df = pd.concat([combined_df, roi_dummies], axis=1)\n",
    "print(\"ROI one-hot encoding completed.\")\n",
    "\n",
    "##################################\n",
    "# 3) DEFINE EXPLICIT FEATURE LIST\n",
    "##################################\n",
    "def get_explicit_feature_list():\n",
    "    # Bandpower features: 5 bands x 3 metrics = 15 features\n",
    "    band_names = ['delta', 'theta', 'alpha', 'beta', 'gamma']\n",
    "    band_features = [f\"{band}_{metric}\" for band in band_names for metric in ['power', 'rel', 'log']]\n",
    "    \n",
    "    # FOOOF features: 5 features\n",
    "    fooof_features = [\n",
    "        'fooof_aperiodic_offset', \n",
    "        'fooof_aperiodic_exponent', \n",
    "        'fooof_r_squared', \n",
    "        'fooof_error', \n",
    "        'fooof_num_peaks'\n",
    "    ]\n",
    "    \n",
    "    # Entropy feature: 1 feature\n",
    "    entropy_features = ['entropy_5secwin']\n",
    "    \n",
    "    # catch22 features: typically ~22 features (depends on pycatch22 output)\n",
    "    dummy = np.random.randn(100).tolist()\n",
    "    res = pycatch22.catch22_all(dummy, catch24=False)\n",
    "    catch22_features = [f\"catch22_{nm}\" for nm in res['names']]\n",
    "    \n",
    "    # ROI one-hot encoded features: all columns that start with \"roiNum\"\n",
    "    roi_features = [col for col in combined_df.columns if col.startswith(\"roiNum\")]\n",
    "    \n",
    "    return band_features + fooof_features + entropy_features + catch22_features + roi_features\n",
    "\n",
    "explicit_feature_list = get_explicit_feature_list()\n",
    "# Only include features present in combined_df:\n",
    "present_features = [feat for feat in explicit_feature_list if feat in combined_df.columns]\n",
    "print(f\"Using explicit feature list with {len(present_features)} features.\")\n",
    "\n",
    "##################################\n",
    "# 4) PREPROCESSING\n",
    "##################################\n",
    "# Drop rows with missing values in the explicit feature columns.\n",
    "combined_df = combined_df.dropna(subset=present_features)\n",
    "X_full = combined_df[present_features].values\n",
    "y_full = combined_df['label'].values\n",
    "\n",
    "##################################\n",
    "# 5) TRAIN-TEST SPLIT AT SUBJECT LEVEL\n",
    "##################################\n",
    "unique_subjects = combined_df['subject_id'].unique()\n",
    "print(\"Total unique subjects:\", len(unique_subjects))\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_subjects, test_subjects = train_test_split(unique_subjects, test_size=0.2, random_state=42)\n",
    "print(\"Training subjects:\", train_subjects)\n",
    "print(\"Testing subjects:\", test_subjects)\n",
    "\n",
    "# Create masks for train and test based on subject_id\n",
    "train_mask = combined_df['subject_id'].isin(train_subjects)\n",
    "test_mask = combined_df['subject_id'].isin(test_subjects)\n",
    "\n",
    "X_train = combined_df[train_mask][present_features].values\n",
    "y_train = combined_df[train_mask]['label'].values\n",
    "X_test = combined_df[test_mask][present_features].values\n",
    "y_test = combined_df[test_mask]['label'].values\n",
    "\n",
    "print(f\"Training set shape: {X_train.shape}\")\n",
    "print(f\"Test set shape: {X_test.shape}\")\n",
    "\n",
    "# Standardize features based on training data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "##################################\n",
    "# 6) TRAIN MODELS USING GROUP-AWARE CROSS-VALIDATION\n",
    "##################################\n",
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "def train_and_evaluate_with_groups(X, y, groups, model_choice='random_forest'):\n",
    "    if model_choice == 'random_forest':\n",
    "        model = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced')\n",
    "    elif model_choice == 'logistic':\n",
    "        model = LogisticRegression(max_iter=1000, random_state=42, class_weight='balanced')\n",
    "    elif model_choice == 'svm':\n",
    "        model = SVC(kernel='rbf', probability=True, random_state=42, class_weight='balanced')\n",
    "    elif model_choice == 'xgboost':\n",
    "        pos = np.sum(y == 1)\n",
    "        neg = np.sum(y == 0)\n",
    "        scale_pos_weight = neg / pos if pos > 0 else 1\n",
    "        model = XGBClassifier(random_state=42, scale_pos_weight=scale_pos_weight,\n",
    "                              use_label_encoder=False, eval_metric='logloss')\n",
    "    else:\n",
    "        raise ValueError(\"model_choice must be one of ['random_forest','logistic','svm','xgboost']\")\n",
    "    \n",
    "    gkf = GroupKFold(n_splits=5)\n",
    "    accuracies, aucs = [], []\n",
    "    for train_idx, val_idx in gkf.split(X, y, groups=groups):\n",
    "        X_train_cv, X_val_cv = X[train_idx], X[val_idx]\n",
    "        y_train_cv, y_val_cv = y[train_idx], y[val_idx]\n",
    "        model.fit(X_train_cv, y_train_cv)\n",
    "        y_pred_cv = model.predict(X_val_cv)\n",
    "        acc = accuracy_score(y_val_cv, y_pred_cv)\n",
    "        accuracies.append(acc)\n",
    "        if hasattr(model, 'predict_proba'):\n",
    "            y_proba_cv = model.predict_proba(X_val_cv)[:, 1]\n",
    "            aucs.append(roc_auc_score(y_val_cv, y_proba_cv))\n",
    "    print(f\"\\n=== {model_choice.upper()} GROUP-CV Results ===\")\n",
    "    print(f\"Accuracy: {np.mean(accuracies):.3f} ± {np.std(accuracies):.3f}\")\n",
    "    if aucs:\n",
    "        print(f\"ROC AUC: {np.mean(aucs):.3f} ± {np.std(aucs):.3f}\")\n",
    "    \n",
    "    # Refit on full training data\n",
    "    model.fit(X, y)\n",
    "    return model\n",
    "\n",
    "# Create a groups vector from training data (subject IDs for each electrode)\n",
    "train_groups = combined_df[train_mask]['subject_id'].values\n",
    "\n",
    "# List of models to train\n",
    "models_to_run = ['random_forest', 'logistic', 'svm', 'xgboost']\n",
    "trained_models = {}\n",
    "\n",
    "for model_name in models_to_run:\n",
    "    print(\"\\n=======================================\")\n",
    "    print(f\"Training Model: {model_name.upper()}\")\n",
    "    clf = train_and_evaluate_with_groups(X_train_scaled, y_train, groups=train_groups, model_choice=model_name)\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    y_pred_test = clf.predict(X_test_scaled)\n",
    "    print(f\"\\n--- {model_name.upper()} TEST SET PERFORMANCE ---\")\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred_test))\n",
    "    if hasattr(clf, 'predict_proba'):\n",
    "        y_proba_test = clf.predict_proba(X_test_scaled)[:, 1]\n",
    "        print(\"ROC AUC:\", roc_auc_score(y_test, y_proba_test))\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred_test, zero_division=0))\n",
    "    cm = confusion_matrix(y_test, y_pred_test)\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)\n",
    "    \n",
    "    trained_models[model_name] = clf\n",
    "\n",
    "##################################\n",
    "# 7) PRINT SUMMARY OF RESULTS\n",
    "##################################\n",
    "print(\"\\n=== Detailed Summary of All Model Results on Test Set ===\")\n",
    "\n",
    "for model_name in models_to_run:\n",
    "    print(\"\\n------------------------------\")\n",
    "    print(f\"Model: {model_name.upper()}\")\n",
    "    model = trained_models[model_name]\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    if hasattr(model, 'predict_proba'):\n",
    "        y_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_test, y_proba)\n",
    "    else:\n",
    "        roc_auc = \"N/A\"\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Accuracy: {accuracy:.3f}\")\n",
    "    print(f\"ROC AUC: {roc_auc}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred, zero_division=0))\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cnt_gen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
