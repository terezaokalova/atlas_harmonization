{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pycatch22\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    roc_auc_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    ConfusionMatrixDisplay\n",
    ")\n",
    "from sklearn.inspection import permutation_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################\n",
    "# 1) DATA LOADING & MERGING\n",
    "############################\n",
    "\n",
    "def convert_spared_to_label(val):\n",
    "    \"\"\"\n",
    "    Convert 'spared' to binary: 0 if spared (TRUE), 1 if resected (FALSE).\n",
    "    \"\"\"\n",
    "    if isinstance(val, bool):\n",
    "        return 0 if val else 1\n",
    "    elif isinstance(val, str):\n",
    "        return 0 if val.strip().upper() == 'TRUE' else 1\n",
    "    else:\n",
    "        return 0 if bool(val) else 1\n",
    "\n",
    "def load_all_subjects(subjects_dir, subject_list):\n",
    "    \"\"\"\n",
    "    Loads each subject's aggregated pickle (sub-XXXX_features_averaged.pkl),\n",
    "    adds a 'subject_id' column, and concatenates into one DataFrame.\n",
    "    \"\"\"\n",
    "    all_dfs = []\n",
    "    for subj in subject_list:\n",
    "        subj_path = os.path.join(subjects_dir, subj)\n",
    "        pkl_file = os.path.join(subj_path, f\"{subj}_features_averaged.pkl\")\n",
    "        if not os.path.isfile(pkl_file):\n",
    "            print(f\"Warning: file not found: {pkl_file}\")\n",
    "            continue\n",
    "        df = pd.read_pickle(pkl_file)\n",
    "        df['subject_id'] = subj\n",
    "        if 'spared' not in df.columns:\n",
    "            raise ValueError(f\"'spared' column missing for {subj}\")\n",
    "        df['label'] = df['spared'].apply(convert_spared_to_label)\n",
    "        all_dfs.append(df)\n",
    "    if not all_dfs:\n",
    "        raise ValueError(\"No data loaded. Check paths or subject list.\")\n",
    "    combined_df = pd.concat(all_dfs, axis=0, ignore_index=True)\n",
    "    return combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "# 2) PREPROCESSING\n",
    "######################\n",
    "\n",
    "# dvakrat meraj raz rez\n",
    "def get_explicit_feature_list():\n",
    "    # Bandpower features for each band\n",
    "    band_names = ['delta', 'theta', 'alpha', 'beta', 'gamma']\n",
    "    band_features = [f\"{band}_{metric}\" for band in band_names for metric in ['power', 'rel', 'log']]\n",
    "    \n",
    "    # FOOOF features.\n",
    "    fooof_features = [\n",
    "        'fooof_aperiodic_offset', \n",
    "        'fooof_aperiodic_exponent', \n",
    "        'fooof_r_squared', \n",
    "        'fooof_error', \n",
    "        'fooof_num_peaks'\n",
    "    ]\n",
    "    \n",
    "    # Entropy feature.\n",
    "    entropy_features = ['entropy_5secwin']\n",
    "    \n",
    "    # Obtain catch22 feature names via a dummy call.\n",
    "    dummy = np.random.randn(100).tolist()\n",
    "    res = pycatch22.catch22_all(dummy, catch24=False)\n",
    "    catch22_features = [f\"catch22_{nm}\" for nm in res['names']]\n",
    "    \n",
    "    return band_features + fooof_features + entropy_features + catch22_features\n",
    "\n",
    "# def get_feature_list(df):\n",
    "#     \"\"\"\n",
    "#     Returns a list of feature columns to use.\n",
    "#     We ignore metadata columns like 'label', 'subject_id', and 'spared'.\n",
    "#     \"\"\"\n",
    "#     ignore_cols = {'label', 'subject_id', 'spared'}\n",
    "#     feature_cols = [col for col in df.columns \n",
    "#                     if col not in ignore_cols and pd.api.types.is_numeric_dtype(df[col])]\n",
    "#     return feature_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "# 3) MODEL TRAINING & EVALUATION\n",
    "######################\n",
    "\n",
    "# runs on subjects (not electrodes)\n",
    "def train_and_evaluate_with_groups(X, y, groups, model_choice='random_forest'):\n",
    "    if model_choice == 'random_forest':\n",
    "        model = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced')\n",
    "    elif model_choice == 'logistic':\n",
    "        model = LogisticRegression(max_iter=1000, random_state=42, class_weight='balanced')\n",
    "    elif model_choice == 'svm':\n",
    "        model = SVC(kernel='rbf', probability=True, random_state=42, class_weight='balanced')\n",
    "    elif model_choice == 'xgboost':\n",
    "        from xgboost import XGBClassifier\n",
    "        # Compute scale_pos_weight to help with imbalance:\n",
    "        pos = np.sum(y == 1)\n",
    "        neg = np.sum(y == 0)\n",
    "        scale_pos_weight = neg / pos if pos > 0 else 1\n",
    "        model = XGBClassifier(scale_pos_weight=scale_pos_weight, random_state=42,\n",
    "                              use_label_encoder=False, eval_metric='logloss')\n",
    "    else:\n",
    "        raise ValueError(\"model_choice must be one of ['random_forest','logistic','svm','xgboost']\")\n",
    "    \n",
    "    gkf = GroupKFold(n_splits=5)\n",
    "    accuracies, aucs = [], []\n",
    "    for train_idx, val_idx in gkf.split(X, y, groups=groups):\n",
    "        X_train_cv, X_val_cv = X[train_idx], X[val_idx]\n",
    "        y_train_cv, y_val_cv = y[train_idx], y[val_idx]\n",
    "        model.fit(X_train_cv, y_train_cv)\n",
    "        y_pred_cv = model.predict(X_val_cv)\n",
    "        acc = accuracy_score(y_val_cv, y_pred_cv)\n",
    "        accuracies.append(acc)\n",
    "        if hasattr(model, 'predict_proba'):\n",
    "            y_proba_cv = model.predict_proba(X_val_cv)[:, 1]\n",
    "            aucs.append(roc_auc_score(y_val_cv, y_proba_cv))\n",
    "    print(f\"\\n=== {model_choice.upper()} GROUP-CV Results ===\")\n",
    "    print(f\"Accuracy: {np.mean(accuracies):.3f} ± {np.std(accuracies):.3f}\")\n",
    "    if aucs:\n",
    "        print(f\"ROC AUC:  {np.mean(aucs):.3f} ± {np.std(aucs):.3f}\")\n",
    "    \n",
    "    # Refit on full training set\n",
    "    model.fit(X, y)\n",
    "    return model\n",
    "\n",
    "# def train_and_evaluate(X, y, model_choice='random_forest'):\n",
    "#     \"\"\"\n",
    "#     Trains a model with 5-fold cross-validation on (X, y) and returns the fitted model.\n",
    "#     Prints mean accuracy and ROC AUC across folds.\n",
    "#     \"\"\"\n",
    "#     if model_choice == 'random_forest':\n",
    "#         model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "#     elif model_choice == 'logistic':\n",
    "#         model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "#     elif model_choice == 'svm':\n",
    "#         model = SVC(kernel='rbf', probability=True, random_state=42)\n",
    "#     else:\n",
    "#         raise ValueError(\"model_choice must be one of ['random_forest','logistic','svm']\")\n",
    "    \n",
    "#     skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "#     accuracies, aucs = [], []\n",
    "#     for train_idx, val_idx in skf.split(X, y):\n",
    "#         X_train_cv, X_val_cv = X[train_idx], X[val_idx]\n",
    "#         y_train_cv, y_val_cv = y[train_idx], y[val_idx]\n",
    "#         model.fit(X_train_cv, y_train_cv)\n",
    "#         y_pred_cv = model.predict(X_val_cv)\n",
    "#         acc = accuracy_score(y_val_cv, y_pred_cv)\n",
    "#         accuracies.append(acc)\n",
    "#         if hasattr(model, 'predict_proba'):\n",
    "#             y_proba_cv = model.predict_proba(X_val_cv)[:, 1]\n",
    "#             aucs.append(roc_auc_score(y_val_cv, y_proba_cv))\n",
    "    \n",
    "#     print(f\"\\n=== {model_choice.upper()} CROSS-VALIDATION ===\")\n",
    "#     print(f\"Accuracy: {np.mean(accuracies):.3f} ± {np.std(accuracies):.3f}\")\n",
    "#     if aucs:\n",
    "#         print(f\"ROC AUC:  {np.mean(aucs):.3f} ± {np.std(aucs):.3f}\")\n",
    "    \n",
    "#     # Fit on full training data\n",
    "#     model.fit(X, y)\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from all subjects...\n",
      "Combined data shape: (1675, 51)\n",
      "Using explicit feature list with 43 features.\n"
     ]
    }
   ],
   "source": [
    "######################\n",
    "# 4) PIPELINE\n",
    "######################\n",
    "\n",
    "# Adjust these paths and subject list to match your setup.\n",
    "subjects_dir = \"/Users/tereza/nishant/atlas/atlas_work_terez/atlas_harmonization/Data/hup/derivatives/clean\"\n",
    "subject_list = [\n",
    "    \"sub-RID0031\", \"sub-RID0032\", \"sub-RID0033\", \"sub-RID0050\", \"sub-RID0051\", \n",
    "    \"sub-RID0064\", \"sub-RID0089\", \"sub-RID0101\", \"sub-RID0117\", \"sub-RID0143\",\n",
    "    \"sub-RID0167\", \"sub-RID0175\", \"sub-RID0179\", \"sub-RID0238\", \"sub-RID0301\",\n",
    "    \"sub-RID0320\", \"sub-RID0381\", \"sub-RID0405\", \"sub-RID0424\", \"sub-RID0508\",\n",
    "    \"sub-RID0562\", \"sub-RID0589\", \"sub-RID0658\"\n",
    "]\n",
    "\n",
    "print(\"Loading data from all subjects...\")\n",
    "combined_df = load_all_subjects(subjects_dir, subject_list)\n",
    "print(f\"Combined data shape: {combined_df.shape}\")\n",
    "\n",
    "# Use the explicit feature list from the extraction script\n",
    "explicit_feature_list = get_explicit_feature_list()\n",
    "# Only include features that are present in the combined DataFrame\n",
    "present_features = [feat for feat in explicit_feature_list if feat in combined_df.columns]\n",
    "print(f\"Using explicit feature list with {len(present_features)} features.\")\n",
    "\n",
    "# Identify feature columns - prev without explicit feature list\n",
    "# feature_cols = get_feature_list(combined_df)\n",
    "# print(f\"Found {len(feature_cols)} feature columns.\")\n",
    "\n",
    "# Drop rows with missing feature values using the explicit feature list\n",
    "combined_df = combined_df.dropna(subset=present_features)\n",
    "X_full = combined_df[present_features].values\n",
    "y_full = combined_df['label'].values\n",
    "\n",
    "# # Drop rows with missing feature values\n",
    "# combined_df = combined_df.dropna(subset=feature_cols)\n",
    "# X_full = combined_df[feature_cols].values\n",
    "# y_full = combined_df['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique subjects: 23\n",
      "Unique subjects: ['sub-RID0031' 'sub-RID0032' 'sub-RID0033' 'sub-RID0050' 'sub-RID0051'\n",
      " 'sub-RID0064' 'sub-RID0089' 'sub-RID0101' 'sub-RID0117' 'sub-RID0143'\n",
      " 'sub-RID0167' 'sub-RID0175' 'sub-RID0179' 'sub-RID0238' 'sub-RID0301'\n",
      " 'sub-RID0320' 'sub-RID0381' 'sub-RID0405' 'sub-RID0424' 'sub-RID0508'\n",
      " 'sub-RID0562' 'sub-RID0589' 'sub-RID0658']\n",
      "Number of training subjects: 18\n",
      "Training subjects: ['sub-RID0179' 'sub-RID0032' 'sub-RID0238' 'sub-RID0064' 'sub-RID0033'\n",
      " 'sub-RID0175' 'sub-RID0562' 'sub-RID0050' 'sub-RID0051' 'sub-RID0424'\n",
      " 'sub-RID0381' 'sub-RID0589' 'sub-RID0658' 'sub-RID0101' 'sub-RID0167'\n",
      " 'sub-RID0301' 'sub-RID0508' 'sub-RID0089']\n",
      "Number of testing subjects: 5\n",
      "Testing subjects: ['sub-RID0320' 'sub-RID0143' 'sub-RID0031' 'sub-RID0117' 'sub-RID0405']\n",
      "Training set shape: (1251, 43)\n",
      "Test set shape: (424, 43)\n"
     ]
    }
   ],
   "source": [
    "#############################\n",
    "# 5) TRAIN-TEST SPLIT (80/20) AT SUBJECT LEVEL\n",
    "#############################\n",
    "\n",
    "# Get the unique subject IDs\n",
    "unique_subjects = combined_df['subject_id'].unique()\n",
    "print(\"Total unique subjects:\", len(unique_subjects))\n",
    "print(\"Unique subjects:\", unique_subjects)\n",
    "\n",
    "# Split subjects into training and testing sets (80/20 split)\n",
    "train_subjects, test_subjects = train_test_split(unique_subjects, test_size=0.2, random_state=42)\n",
    "print(\"Number of training subjects:\", len(train_subjects))\n",
    "print(\"Training subjects:\", train_subjects)\n",
    "print(\"Number of testing subjects:\", len(test_subjects))\n",
    "print(\"Testing subjects:\", test_subjects)\n",
    "\n",
    "# Create masks to select rows for train and test based on subject_id\n",
    "train_mask = combined_df['subject_id'].isin(train_subjects)\n",
    "test_mask = combined_df['subject_id'].isin(test_subjects)\n",
    "\n",
    "# Use the explicit feature list variable 'present_features'\n",
    "X_train = combined_df[train_mask][present_features].values\n",
    "y_train = combined_df[train_mask]['label'].values\n",
    "\n",
    "X_test = combined_df[test_mask][present_features].values\n",
    "y_test = combined_df[test_mask]['label'].values\n",
    "\n",
    "print(f\"Training set shape: {X_train.shape}\")\n",
    "print(f\"Test set shape: {X_test.shape}\")\n",
    "\n",
    "# Standardize features based on the training set\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# # Here, we perform a random 80/20 split at the electrode level.\n",
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     X_full, y_full, test_size=0.2, stratify=y_full, random_state=42\n",
    "# )\n",
    "\n",
    "# # Standardize features based on the training set\n",
    "# scaler = StandardScaler()\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "# X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=======================================\n",
      "Training Model: XGBOOST\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tereza/anaconda3/envs/cnt_gen/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:10:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/tereza/anaconda3/envs/cnt_gen/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:10:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/tereza/anaconda3/envs/cnt_gen/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:10:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/tereza/anaconda3/envs/cnt_gen/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:10:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/tereza/anaconda3/envs/cnt_gen/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:10:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== XGBOOST GROUP-CV Results ===\n",
      "Accuracy: 0.830 ± 0.038\n",
      "ROC AUC:  0.607 ± 0.083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tereza/anaconda3/envs/cnt_gen/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:10:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- XGBOOST TEST SET PERFORMANCE ---\n",
      "Accuracy: 0.7971698113207547\n",
      "ROC AUC: 0.5818537286039183\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.94      0.89       353\n",
      "           1       0.24      0.10      0.14        71\n",
      "\n",
      "    accuracy                           0.80       424\n",
      "   macro avg       0.54      0.52      0.51       424\n",
      "weighted avg       0.74      0.80      0.76       424\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfsAAAHHCAYAAAC4M/EEAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy80BEi2AAAACXBIWXMAAA9hAAAPYQGoP6dpAABF0klEQVR4nO3deVhU5fs/8PcAzrAOiMqmiOKCklupGZlbErjm1rc0SzCXMjQV93LF1H7aJ3el0kT9aJaVluYSaoomuZDkjkooFAyaCAjKNvP8/vDD5AToDDMwzpz367rOdTnnPM859xm5uLmf85xzZEIIASIiIrJaNuYOgIiIiKoWkz0REZGVY7InIiKyckz2REREVo7JnoiIyMox2RMREVk5JnsiIiIrx2RPRERk5ZjsiYiIrByTPZnU1atXERISAldXV8hkMuzcudOk+79+/TpkMhliYmJMul9L1rVrV3Tt2tXcYRDRE4zJ3golJyfj7bffhr+/P+zt7aFUKtGxY0csX74c9+/fr9Jjh4WF4dy5c1iwYAE2b96Mdu3aVenxqlN4eDhkMhmUSmW53+PVq1chk8kgk8nw8ccfG7z/9PR0zJ07F4mJiSaItupdvHgRcrkcw4cPL7MtOzsb3t7e6NChAzQajc62s2fPYvjw4WjYsCHs7e3h7OyMNm3aYOrUqfjjjz902pZ+56WLnZ0dfH19MXjwYFy8eLHcuH755RcMGDAAnp6eUCgUaNCgAd5++22kpqZWeC6G9jl27Bh69uyJunXrwt7eHvXr10ffvn2xdevWcuOuaAkPD3/UV0xkMnbmDoBM68cff8T//d//QaFQYNiwYWjRogWKiopw7NgxTJkyBRcuXMBnn31WJce+f/8+4uPj8cEHH2Ds2LFVcgw/Pz/cv38fNWrUqJL9P46dnR3u3buHXbt24dVXX9XZtmXLFtjb26OgoKBS+05PT8e8efPQoEEDtGnTRu9+P/30U6WOZ6zAwEBMmTIFCxcuRHh4OLp06aLdNn36dNy6dQt79+6Fjc0/NcXnn3+OMWPGoHbt2hg6dCiaNWuGkpISnD9/Hps2bcKyZctw//592NraavsoFAqsW7cOAFBSUoLk5GRER0dj3759uHjxInx8fLRtV65cifHjx8Pf3x/jxo2Dt7c3Ll26hHXr1uGrr77Cnj178Pzzz+uch6F9tm/fjtdeew1t2rTB+PHjUbNmTaSkpCAuLg6ff/45Xn/9dbz99tsIDg7W9klJScHs2bMxevRodOrUSbu+UaNGJvifINKDIKvxxx9/CGdnZ9GsWTORnp5eZvvVq1fFsmXLquz4N27cEADEkiVLquwY5hQWFiacnJxESEiI6N+/f5ntTZo0EYMGDar0d3Dq1CkBQGzYsEGv9vn5+QYfw9Tu378vGjVqJAICAkRhYaEQQojjx48LmUwmIiMjddr+8ssvwtbWVnTu3Fnk5uaWu6+ZM2eKkpIS7brS7/zfdu/eLQCIzz77TLvu2LFjwsbGRnTq1KnMd3Pt2jXh6ekpvL29RVZWllF9AgMDxVNPPaU934dlZmaW+z0Z+n9LZGpM9lbknXfeEQDEL7/8olf74uJiERUVJfz9/YVcLhd+fn5ixowZoqCgQKedn5+f6N27tzh69Kho3769UCgUomHDhmLjxo3aNnPmzBEAdBY/Pz8hxINf2KX/flhpn4f99NNPomPHjsLV1VU4OTmJpk2bihkzZmi3p6SklPtL8+DBg+KFF14Qjo6OwtXVVbz88svi4sWL5R7v6tWrIiwsTLi6ugqlUinCw8P1SpyliScmJkYoFApx584d7baTJ08KAOLbb78tk+xv374tJk2aJFq0aCGcnJyEi4uL6NGjh0hMTNS2+fnnn8t8fw+fZ5cuXcRTTz0lTp8+LTp16iQcHBzE+PHjtdu6dOmi3dewYcOEQqEoc/4hISHCzc1N/PXXX489V0P89NNPAoCYO3euKCoqEi1atBD169cXeXl5ZY5vZ2cn0tLS9N53Rcn+9OnTAoD44osvtOtCQ0OFra2t+OOPP8rd18aNGwUAsWjRIqP6KBQKER4ervc5CMFkT+bHZG9F6tatK/z9/fVuHxYWJgCIV155RaxevVoMGzZMAChTtfr5+YmAgADh6ekp3n//fbFq1SrxzDPPCJlMJs6fPy+EEOL3338XS5cuFQDEkCFDxObNm8WOHTu0x9En2Z8/f17I5XLRrl07sXz5chEdHS0mT54sOnfurG1TXrKPjY0VdnZ2omnTpmLx4sVi3rx5onbt2qJmzZoiJSWlzPGefvppMXDgQLFmzRoxcuRIAUBMnTpVr+/LyclJ5ObmCnt7e7F+/XrttgkTJohmzZpp43s42Z86dUo0atRITJ8+XXz66aciKipK1K1bV7i6umoTr0qlElFRUQKAGD16tNi8ebPYvHmzSE5OFkI8SOheXl6iTp06Yty4ceLTTz8VO3fu1G57ONnfuXNH1KtXT7Rv315bJUdHRwsAYvPmzY89z8oYMmSIUCgUYvTo0QKA+P7773W25+fnCzs7OxEcHGzQfku/81u3bolbt24JlUoljh8/Ljp16iRq1aolbt68qbP/rl27VrivgoICoVAoRMeOHSvdRwghmjZtKnx9fQ36o4XJnsyNyd5K5OTkCACiX79+erVPTEwUAMTIkSN11k+ePFkAEIcOHdKu8/PzEwBEXFycdt3NmzeFQqEQkyZN0q4rL9EJoX+yL/1j4datWxXGXV6yb9OmjfDw8BC3b9/Wrvv999+FjY2NGDZsWJnjvfXWWzr7HDBggKhVq1aFx3z4PEqrzFdeeUV0795dCCGEWq0WXl5eYt68eeV+BwUFBUKtVpc5D4VCIaKiorTrHpUQunTpIgCI6Ojocrc9nOyFEGL//v0CgPjwww+1l3fKu/RgKiqVStSsWbPcPxaFePD/AUBMmDChzLbbt29rk/mtW7d0hsdL/yD991K3bl2RkJCgbVf681w62lGRVq1aCXd390r3EUKI9evXCwBCLpeLbt26iVmzZomjR4+W+T9+GJM9mRtn41uJ3NxcAICLi4te7ffs2QMAiIyM1Fk/adIkAA8m+j0sMDBQZ2JRnTp1EBAQUGb2tDHc3NwAAN9//32ZGdwVycjIQGJiIsLDw+Hu7q5d36pVK7z00kva83zYO++8o/O5U6dOuH37tvY71Mfrr7+Ow4cPQ6VS4dChQ1CpVHj99dfLbatQKLST1NRqNW7fvg1nZ2cEBATgt99+0/uYCoWi3Jnv5QkJCcHbb7+NqKgoDBw4EPb29vj000/1PpahHB0d4ejoqD32v5V+t87OzmW2+fv7o06dOtrlhx9+0Nlub2+P2NhYxMbGYv/+/fj000/h7OyMXr164cqVKwCAu3fvAnj8z7+Li4s2lsr0AYC33noL+/btQ9euXXHs2DHMnz8fnTp1QpMmTXD8+PFH7ovIXJjsrYRSqQTwzy+wx7lx4wZsbGzQuHFjnfVeXl5wc3PDjRs3dNbXr1+/zD5q1qyJO3fuVDLisl577TV07NgRI0eOhKenJwYPHoyvv/76kYm/NM6AgIAy25o3b46///4b+fn5Ouv/fS41a9YEAIPOpVevXnBxccFXX32FLVu2oH379mW+y1IajQZLly5FkyZNoFAoULt2bdSpUwdnz55FTk6O3sesW7cu5HK53u0//vhjuLu7IzExEStWrICHh8dj+9y6dQsqlUq75OXl6XWsDz74ACqVCs2bN8ecOXPKfJelCbW8/X3//feIjY2t8HZFW1tbBAcHIzg4GCEhIRg9ejQOHDiAnJwczJgxQ2f/j/v5v3v3rrZtZfqUCg0Nxf79+5GdnY24uDhERETgxo0b6NOnD27evPnI/RGZA5O9lVAqlfDx8cH58+cN6ieTyfRq9/CtUA8TQlT6GGq1Wuezg4MD4uLicODAAbz55ps4e/YsXnvtNbz00ktl2hrDmHMppVAoMHDgQGzcuBE7duyosKoHgIULFyIyMhKdO3fGf//7X+zfvx+xsbF46qmn9B7BAB58P4Y4c+aMNvGcO3dOrz7t27eHt7e3dtHneQGnT5/G6tWrMW7cOGzbtg137tzBtGnTdNo0btwYdnZ25f58dunSBcHBwWjbtq1eMQJAvXr1EBAQgLi4OJ39nz17tsI+hYWFSEpKQmBgYKX7/JujoyM6deqEVatWYebMmbhz5w727t2r93kQVRcmeyvSp08fJCcnIz4+/rFt/fz8oNFocPXqVZ31mZmZyM7Ohp+fn8niqlmzJrKzs8us//foAQDY2Nige/fu+OSTT3Dx4kUsWLAAhw4dws8//1zuvkvjTEpKKrPt8uXLqF27NpycnIw7gQq8/vrrOHPmDO7evYvBgwdX2O6bb75Bt27dsH79egwePBghISEIDg4u853o+4eXPvLz8zF8+HAEBgZi9OjRWLx4MU6dOvXYflu2bNEOmcfGxmLYsGGPbK9WqzF69Gj4+PggKioKrVq1wvjx47Fu3Tqdn0MnJyd07doVR44cwV9//WX0+QEP7rkvHSlwcnJCt27dEBcXV+7PFQB8/fXXKCwsRJ8+fSrd51FKHyCVkZFRmdMhqlJM9lZk6tSpcHJywsiRI5GZmVlme3JyMpYvXw7gwTA0ACxbtkynzSeffAIA6N27t8niatSoEXJycnQqqIyMDOzYsUOnXVZWVpm+pQ+XKSwsLHff3t7eaNOmDTZu3KiTPM+fP4+ffvpJe55VoVu3bpg/fz5WrVoFLy+vCtvZ2tqWGTXYvn17maRX+kdJeX8YGWratGlITU3Fxo0b8cknn6BBgwYICwur8Hss1bFjR+2QeXBwMPz9/R/ZfsWKFThz5gxWrFihHeqeN28e6tWrh3feeQclJSXatrNnz4ZarcYbb7xR7nC+ISMrV65cQVJSElq3bq1dN3PmTAghEB4eXuYJhykpKZg6dSq8vb3x9ttvG9Xn4MGD5cZUOj+kvEtKRObGJ+hZkUaNGmHr1q147bXX0Lx5c50n6B0/fhzbt2/XPp6zdevWCAsLw2effYbs7Gx06dIFJ0+exMaNG9G/f39069bNZHENHjwY06ZNw4ABA/Dee+/h3r17WLt2LZo2baozQS0qKgpxcXHo3bs3/Pz8cPPmTaxZswb16tXDCy+8UOH+lyxZgp49eyIoKAgjRozA/fv3sXLlSri6umLu3LkmO49/s7GxwcyZMx/brk+fPoiKisLw4cPx/PPP49y5c9iyZUuZRNqoUSO4ubkhOjoaLi4ucHJyQocOHdCwYUOD4jp06BDWrFmDOXPm4JlnngEAbNiwAV27dsWsWbOwePFig/ZXkbS0NMyePRt9+/bFgAEDtOudnJywfPlyDBw4EMuXL9dO+iwd7h43bhyaNGmifYJeUVERrly5gi1btkAul5f5w6mkpAT//e9/ATyY/3D9+nVER0dDo9Fgzpw52nadO3fGxx9/jMjISLRq1Qrh4eHw9vbG5cuX8fnnn0Oj0WDPnj3aORqV7dOvXz80bNgQffv2RaNGjZCfn48DBw5g165daN++Pfr27WuS75fIpMx5KwBVjStXrohRo0aJBg0aCLlcLlxcXETHjh3FypUrdR6YU1xcLObNmycaNmwoatSoIXx9fR/5UJ1/+/ctXxXdeifEgwevtGjRQsjlchEQECD++9//lrn17uDBg6Jfv37Cx8dHyOVy4ePjI4YMGSKuXLlS5hj/voXpwIEDomPHjsLBwUEolUrRt2/fCh+q8+9b+zZs2CAA6NyTX56KHvDysIpuvZs0aZLw9vYWDg4OomPHjiI+Pr7cW+a+//57ERgYKOzs7Mp9qE55Ht5Pbm6u8PPzE88884woLi7WaTdx4kRhY2Mj4uPjH3kO+urXr59wcnISN27cKHd7nz59hLOzs0hNTdVZf+bMGTFs2DBRv359IZfLhZOTk2jVqpWYNGmSuHbtmk7b8m69UyqVonv37uLAgQPlHjcuLk7069dP1K5dW9SoUUPUr19fjBo1Sly/fr3CczGkz5dffikGDx4sGjVqJBwcHIS9vb0IDAwUH3zwQblPBhSCt96R+cmEMGDsjIiIiCwOr9kTERFZOSZ7IiIiK8dkT0REZOWY7ImIiKwckz0REZGVY7InIiKychb9UB2NRoP09HS4uLiY9FGjRERUPYQQuHv3Lnx8fLRvh6wKBQUFKCoqMno/crkc9vb2Joioell0sk9PT4evr6+5wyAiIiOlpaWhXr16VbLvgoICNPRzhuqm8S/U8vLyQkpKisUlfItO9qXP4r7xWwMonXlFgqzTK892NHcIRFWmRBThSM5XZV4jbEpFRUVQ3VTjRkIDKF0qnyty72rg1/Y6ioqKmOyrU+nQvdLZxqj/QKInmZ1M/3fYE1mq6rgU6+wig7NL5Y+jgeVeLrboZE9ERKQvtdBAbcQD4tVCY7pgqhmTPRERSYIGAhpUPtsb09fcOPZNRERk5VjZExGRJGiggTED8cb1Ni8meyIikgS1EFAb8VZ3Y/qaG4fxiYiIrBwreyIikgQpT9BjsiciIknQQEAt0WTPYXwiIiIrx8qeiIgkgcP4REREVo6z8YmIiMhqsbInIiJJ0PxvMaa/pWKyJyIiSVAbORvfmL7mxmRPRESSoBYw8q13pouluvGaPRERkZVjZU9ERJLAa/ZERERWTgMZ1JAZ1d9ScRifiIjIyrGyJyIiSdCIB4sx/S0Vkz0REUmC2shhfGP6mhuH8YmIiKwcK3siIpIEKVf2TPZERCQJGiGDRhgxG9+IvubGYXwiIiIrx8qeiIgkgcP4REREVk4NG6iNGNBWmzCW6sZkT0REkiCMvGYveM2eiIiIHrZ27Vq0atUKSqUSSqUSQUFB2Lt3r3Z7QUEBIiIiUKtWLTg7O2PQoEHIzMzU2Udqaip69+4NR0dHeHh4YMqUKSgpKTE4FiZ7IiKShNJr9sYshqhXrx4++ugjJCQk4PTp03jxxRfRr18/XLhwAQAwceJE7Nq1C9u3b8eRI0eQnp6OgQMH/hOvWo3evXujqKgIx48fx8aNGxETE4PZs2cbfO4yIYTFPgAwNzcXrq6uuHPFH0oX/t1C1qlXYBdzh0BUZUpEEQ5mb0ZOTg6USmWVHKM0V+w92xBORuSK/Lsa9GyVYlSs7u7uWLJkCV555RXUqVMHW7duxSuvvAIAuHz5Mpo3b474+Hg899xz2Lt3L/r06YP09HR4enoCAKKjozFt2jTcunULcrlc7+MyQxIRERkgNzdXZyksLHxsH7VajW3btiE/Px9BQUFISEhAcXExgoODtW2aNWuG+vXrIz4+HgAQHx+Pli1bahM9AISGhiI3N1c7OqAvJnsiIpIEDWTQwMaI5cEwvq+vL1xdXbXLokWLKjzmuXPn4OzsDIVCgXfeeQc7duxAYGAgVCoV5HI53NzcdNp7enpCpVIBAFQqlU6iL91eus0QnI1PRESSYKr77NPS0nSG8RUKRYV9AgICkJiYiJycHHzzzTcICwvDkSNHKh1DZTHZExERGaB0dr0+5HI5GjduDABo27YtTp06heXLl+O1115DUVERsrOzdar7zMxMeHl5AQC8vLxw8uRJnf2VztYvbaMvDuMTEZEkqIWN0YuxNBoNCgsL0bZtW9SoUQMHDx7UbktKSkJqaiqCgoIAAEFBQTh37hxu3rypbRMbGwulUonAwECDjsvKnoiIJOHBNXsjXoRjYN8ZM2agZ8+eqF+/Pu7evYutW7fi8OHD2L9/P1xdXTFixAhERkbC3d0dSqUS48aNQ1BQEJ577jkAQEhICAIDA/Hmm29i8eLFUKlUmDlzJiIiIh556aA8TPZERERV4ObNmxg2bBgyMjLg6uqKVq1aYf/+/XjppZcAAEuXLoWNjQ0GDRqEwsJChIaGYs2aNdr+tra22L17N8aMGYOgoCA4OTkhLCwMUVFRBsfC++yJnnC8z56sWXXeZ7/992ZwdLGt9H7u3VXj/1pfrtJYqworeyIikgRjr7urLbc2ZrInIiJpKL1fvvL9LTfZc+ybiIjIyrGyJyIiSVALGdRGvKbWmL7mxmRPRESSoIYN1EYMaKs5jE9ERERPKlb2REQkCRphA40Rs/E1nI1PRET0ZOMwPhEREVktVvZERCQJGhg3o15julCqHZM9ERFJgvEP1bHcwXDLjZyIiIj0wsqeiIgkwfhn41tufcxkT0REklDd77N/kjDZExGRJEi5srfcyImIiEgvrOyJiEgSjH+ojuXWx0z2REQkCRohg8aY++wt+K13lvtnChEREemFlT0REUmCxshhfEt+qA6TPRERSYLxb72z3GRvuZETERGRXljZExGRJKghg9qIB+MY09fcmOyJiEgSOIxPREREVouVPRERSYIaxg3Fq00XSrVjsiciIkmQ8jA+kz0REUkCX4RDREREVouVPRERSYIw8n32grfeERERPdk4jE9ERERWi5U9ERFJgpRfcctkT0REkqA28q13xvQ1N8uNnIiIiPTCyp6IiCSBw/hERERWTgMbaIwY0Damr7lZbuRERESkF1b2REQkCWohg9qIoXhj+pobkz0REUkCr9kTERFZOWHkW+8En6BHRERETypW9kREJAlqyKA24mU2xvQ1NyZ7IiKSBI0w7rq7RpgwmGrGYXwiIiIrx8pe4nZtrIUfN9VGZpocAOAXUIChE1Vo/+JdAMDyqfVw5qgLbmfWgIOjBs3b5WPEB+mo36RQu481M+viwikn3Eiyh2/jQqw9kGSWcyHS16ujUvF88N+o538fRQU2uJSoxBf/aYi/rjsCAJxdi/HG2Bt45vk7qONdiJw7NRB/sBY2r2iAe3n8tWmpNEZO0DOmr7k9EZGvXr0aDRo0gL29PTp06ICTJ0+aOyTJqONdjLfeT8eqfUlYufcKWne8i7nDG+J6kj0AoEmr+5i0NBWfH7mMBVuTAQG8P6QR1Grd/YQOzkLnl7Or/wSIKqFFuxzs/tIHkUPa4IORLWFrJ7Bg3TkoHB78YNeqU4RadYqwbok/xvRri6XvN0W7F+5gwvwrZo6cjKGBzOjFEIsWLUL79u3h4uICDw8P9O/fH0lJusVQ165dIZPJdJZ33nlHp01qaip69+4NR0dHeHh4YMqUKSgpKTEoFrP/ifrVV18hMjIS0dHR6NChA5YtW4bQ0FAkJSXBw8PD3OFZvedCcnU+D5+uwu5NtXE5wRENAgrQ643b2m1evkDYtAyMCW6GzDQ5fBoUAQDe/fAvAEDObS+kXHSovuCJKmn22y11Pn/yflNs++VXNAm8i/MJbrhxzQkLJgRqt6vSHLBxeQNM+X+XYWMroFFb7kQtqj5HjhxBREQE2rdvj5KSErz//vsICQnBxYsX4eTkpG03atQoREVFaT87Ojpq/61Wq9G7d294eXnh+PHjyMjIwLBhw1CjRg0sXLhQ71jMnuw/+eQTjBo1CsOHDwcAREdH48cff8QXX3yB6dOnmzk6aVGrgaO73FB4zwbN2+WX2V5wzwY/feUOr/qFqONTbIYIiaqGk8uDiv5uTo2K2ziX4F6eHRO9BavuJ+jt27dP53NMTAw8PDyQkJCAzp07a9c7OjrCy8ur3H389NNPuHjxIg4cOABPT0+0adMG8+fPx7Rp0zB37lzI5XK9YjHrMH5RURESEhIQHBysXWdjY4Pg4GDEx8ebMTJpSblkj36NW6JPg9ZYMd0Xs9enwK/pP9fkd8XUQr/GLdGvcSucOqTEom3JqCG34GmpRA+RyQTenp6MCwlK3LjmVG4bpVsxhoxJxd7t5f9CJstQes3emMUYOTk5AAB3d3ed9Vu2bEHt2rXRokULzJgxA/fu3dNui4+PR8uWLeHp6aldFxoaitzcXFy4cEHvY5u1sv/777+hVqt1TgIAPD09cfny5TLtCwsLUVj4TxLKzc0t04YMV69RIdbEJuHeXVsc3e2Gj8f7Ycl3V7UJ/8WBd/BM57vIulkD36z1wIK3G2Dp91cht2fCJ8v37qxr8GuSj8lvtCl3u4NTCeZFn0dqsiO2rPar3uDoifTv3KNQKKBQKB7ZR6PRYMKECejYsSNatGihXf/666/Dz88PPj4+OHv2LKZNm4akpCR89913AACVSlVujizdpi+zD+MbYtGiRZg3b565w7A6NeQCdRs+uP7epNV9JCU6Yue6Ohi/+E8AgJNSAydlEer6F6HZM9cxqHkL/LLXFd0GZJsxaiLjjfngGp7tchtTh7XG7cyyv6wdHEsw/7PzuJdvi/njnoK65ImY00yVpIGRz8b/3wQ9X19fnfVz5szB3LlzH9k3IiIC58+fx7Fjx3TWjx49Wvvvli1bwtvbG927d0dycjIaNWpU6Vj/zazJvnbt2rC1tUVmZqbO+szMzHKvX8yYMQORkZHaz7m5uWW+dDKeEEBxUfm/1IQAIGQVbieyDAJjPkhGUPDfmB7eGpl/lZ1Y6uBUgg8/P4fiIhtERTzFn3krICoxo/7f/QEgLS0NSqVSu/5xVf3YsWOxe/duxMXFoV69eo9s26FDBwDAtWvX0KhRI3h5eZW5Q600Z1Z0nb88Zv3plcvlaNu2LQ4ePKhdp9FocPDgQQQFBZVpr1AooFQqdRYyzhcLvXHuVyeo0uRIuWSPLxZ64+xxZ3QbkIWMG3JsW+mBq2cdcPPPGrhwyhELRjeA3EGDZ7v/M4z1V4ocyecdkHXLDkUFMiSfd0DyeQcUF3EiEz2Z3p11Dd36ZmLxlGa4n2+LmrWLULN2EeSKBxP1HJxKsGDdOdg7aLBsVlM4Oqu1bWxsePnKUpW+9c6YBUCZPFRRshdCYOzYsdixYwcOHTqEhg0bPjbGxMREAIC3tzcAICgoCOfOncPNmze1bWJjY6FUKhEYGFjeLspl9mH8yMhIhIWFoV27dnj22WexbNky5Ofna2fnU9XK/tsOS97zQ9ZNOzi6qNGweQEWbE1G2y55uK2yw/kTztjxeR3k5djCrXYJWj6Xh6XfX4Vb7X/u8Vw2uT7OxjtrP78bEgAA2HjiIrx8i6r9nIgep8+QDADA4k1nddZ/8n5THNjphcaBeWjW+sGDpb7Yf0qnTXjws7iZbl89gZJFi4iIwNatW/H999/DxcVFe43d1dUVDg4OSE5OxtatW9GrVy/UqlULZ8+excSJE9G5c2e0atUKABASEoLAwEC8+eabWLx4MVQqFWbOnImIiIjHjig8TCaEMPufqatWrcKSJUugUqnQpk0brFixQjuU8Si5ublwdXXFnSv+ULpwiI2sU6/ALuYOgajKlIgiHMzejJycnCobrS3NFQNih6OGk363qpWnOL8IO17aoHesMln5o5sbNmxAeHg40tLS8MYbb+D8+fPIz8+Hr68vBgwYgJkzZ+rs/8aNGxgzZgwOHz4MJycnhIWF4aOPPoKdnf71utkre+DB9YyxY8eaOwwiIrJiDw/FV7a/IR5XS/v6+uLIkSOP3Y+fnx/27Nlj0LH/jeUwERGRlXsiKnsiIqKqVpnn2/+7v6VisiciIkmo7mH8JwmH8YmIiKwcK3siIpIEKVf2TPZERCQJUk72HMYnIiKycqzsiYhIEqRc2TPZExGRJAgYd/uc2R83awQmeyIikgQpV/a8Zk9ERGTlWNkTEZEkSLmyZ7InIiJJkHKy5zA+ERGRlWNlT0REkiDlyp7JnoiIJEEIGYQRCduYvubGYXwiIiIrx8qeiIgkge+zJyIisnJSvmbPYXwiIiIrx8qeiIgkQcoT9JjsiYhIEqQ8jM9kT0REkiDlyp7X7ImIiKwcK3siIpIEYeQwviVX9kz2REQkCQKAEMb1t1QcxiciIrJyrOyJiEgSNJBBxifoERERWS/OxiciIiKrxcqeiIgkQSNkkPGhOkRERNZLCCNn41vwdHwO4xMREVk5VvZERCQJUp6gx2RPRESSwGRPRERk5aQ8QY/X7ImIiKwcK3siIpIEKc/GZ7InIiJJeJDsjblmb8JgqhmH8YmIiKwcK3siIpIEzsYnIiKycgLGvZPegkfxOYxPRERk7VjZExGRJHAYn4iIyNpJeByfyZ6IiKTByMoeFlzZ85o9ERFRFVi0aBHat28PFxcXeHh4oH///khKStJpU1BQgIiICNSqVQvOzs4YNGgQMjMzddqkpqaid+/ecHR0hIeHB6ZMmYKSkhKDYmGyJyIiSSh9gp4xiyGOHDmCiIgI/Prrr4iNjUVxcTFCQkKQn5+vbTNx4kTs2rUL27dvx5EjR5Ceno6BAwdqt6vVavTu3RtFRUU4fvw4Nm7ciJiYGMyePdugWDiMT0REklDdE/T27dun8zkmJgYeHh5ISEhA586dkZOTg/Xr12Pr1q148cUXAQAbNmxA8+bN8euvv+K5557DTz/9hIsXL+LAgQPw9PREmzZtMH/+fEybNg1z586FXC7XKxZW9kRERNUgJycHAODu7g4ASEhIQHFxMYKDg7VtmjVrhvr16yM+Ph4AEB8fj5YtW8LT01PbJjQ0FLm5ubhw4YLex2ZlT0RE0iBkxk2y+1/f3NxcndUKhQIKheKRXTUaDSZMmICOHTuiRYsWAACVSgW5XA43Nzedtp6enlCpVNo2Dyf60u2l2/TFyp6IiCTBVNfsfX194erqql0WLVr02GNHRETg/Pnz2LZtWxWfZflY2RMRERkgLS0NSqVS+/lxVf3YsWOxe/duxMXFoV69etr1Xl5eKCoqQnZ2tk51n5mZCS8vL22bkydP6uyvdLZ+aRt9sLInIiJpECZYACiVSp2lomQvhMDYsWOxY8cOHDp0CA0bNtTZ3rZtW9SoUQMHDx7UrktKSkJqaiqCgoIAAEFBQTh37hxu3rypbRMbGwulUonAwEC9T12vyv6HH37Qe4cvv/yy3m2JiIiqS3XPxo+IiMDWrVvx/fffw8XFRXuN3dXVFQ4ODnB1dcWIESMQGRkJd3d3KJVKjBs3DkFBQXjuuecAACEhIQgMDMSbb76JxYsXQ6VSYebMmYiIiHjsiMLD9Er2/fv312tnMpkMarVa74MTERFZq7Vr1wIAunbtqrN+w4YNCA8PBwAsXboUNjY2GDRoEAoLCxEaGoo1a9Zo29ra2mL37t0YM2YMgoKC4OTkhLCwMERFRRkUi17JXqPRGLRTIiKiJ1I1Pt9e6PEUHnt7e6xevRqrV6+usI2fnx/27NljVCxGTdArKCiAvb29UQEQERFVBym/9c7gCXpqtRrz589H3bp14ezsjD/++AMAMGvWLKxfv97kARIREZmEiSboWSKDk/2CBQsQExODxYsX6zymr0WLFli3bp1JgyMiIiLjGZzsN23ahM8++wxDhw6Fra2tdn3r1q1x+fJlkwZHRERkOjITLJbJ4Gv2f/31Fxo3blxmvUajQXFxsUmCIiIiMjljh+KlNIwfGBiIo0ePlln/zTff4OmnnzZJUERERGQ6Blf2s2fPRlhYGP766y9oNBp89913SEpKwqZNm7B79+6qiJGIiMh4rOz1169fP+zatQsHDhyAk5MTZs+ejUuXLmHXrl146aWXqiJGIiIi45W+9c6YxUJV6j77Tp06ITY21tSxEBERURWo9EN1Tp8+jUuXLgF4cB2/bdu2JguKiIjI1B5+TW1l+1sqg5P9n3/+iSFDhuCXX37RvpIvOzsbzz//PLZt26bz+j4iIqInBq/Z62/kyJEoLi7GpUuXkJWVhaysLFy6dAkajQYjR46sihiJiIjICAZX9keOHMHx48cREBCgXRcQEICVK1eiU6dOJg2OiIjIZIydZCelCXq+vr7lPjxHrVbDx8fHJEERERGZmkw8WIzpb6kMHsZfsmQJxo0bh9OnT2vXnT59GuPHj8fHH39s0uCIiIhMRsIvwtGrsq9ZsyZksn+GL/Lz89GhQwfY2T3oXlJSAjs7O7z11lvo379/lQRKRERElaNXsl+2bFkVh0FERFTFeM3+0cLCwqo6DiIioqol4VvvKv1QHQAoKChAUVGRzjqlUmlUQERERGRaBk/Qy8/Px9ixY+Hh4QEnJyfUrFlTZyEiInoiSXiCnsHJfurUqTh06BDWrl0LhUKBdevWYd68efDx8cGmTZuqIkYiIiLjSTjZGzyMv2vXLmzatAldu3bF8OHD0alTJzRu3Bh+fn7YsmULhg4dWhVxEhERUSUZXNlnZWXB398fwIPr81lZWQCAF154AXFxcaaNjoiIyFQk/Ipbg5O9v78/UlJSAADNmjXD119/DeBBxV/6YhwiIqInTekT9IxZLJXByX748OH4/fffAQDTp0/H6tWrYW9vj4kTJ2LKlCkmD5CIiIiMY/A1+4kTJ2r/HRwcjMuXLyMhIQGNGzdGq1atTBocERGRyfA++8rz8/ODn5+fKWIhIiKiKqBXsl+xYoXeO3zvvfcqHQwREVFVkcHIt96ZLJLqp1eyX7p0qV47k8lkTPZERERPGL2Sfens+ydV/2Gvw87O3txhEFUJWXaiuUMgqjJqUVx9B+OLcIiIiKychCfoGXzrHREREVkWVvZERCQNEq7smeyJiEgSjH0KnqSeoEdERESWpVLJ/ujRo3jjjTcQFBSEv/76CwCwefNmHDt2zKTBERERmYyEX3FrcLL/9ttvERoaCgcHB5w5cwaFhYUAgJycHCxcuNDkARIREZkEk73+PvzwQ0RHR+Pzzz9HjRo1tOs7duyI3377zaTBERERkfEMnqCXlJSEzp07l1nv6uqK7OxsU8RERERkcpygZwAvLy9cu3atzPpjx47B39/fJEERERGZXOkT9IxZLJTByX7UqFEYP348Tpw4AZlMhvT0dGzZsgWTJ0/GmDFjqiJGIiIi40n4mr3Bw/jTp0+HRqNB9+7dce/ePXTu3BkKhQKTJ0/GuHHjqiJGIiIiMoLByV4mk+GDDz7AlClTcO3aNeTl5SEwMBDOzs5VER8REZFJSPmafaWfoCeXyxEYGGjKWIiIiKoOH5erv27dukEmq3iSwqFDh4wKiIiIiEzL4GTfpk0bnc/FxcVITEzE+fPnERYWZqq4iIiITMvIYXxLruwNno2/dOlSnWXVqlU4duwYJkyYoPOQHSIioidKNc/Gj4uLQ9++feHj4wOZTIadO3fqbA8PD4dMJtNZevToodMmKysLQ4cOhVKphJubG0aMGIG8vDwDT9yEL8J544038MUXX5hqd0RERBYtPz8frVu3xurVqyts06NHD2RkZGiXL7/8Umf70KFDceHCBcTGxmL37t2Ii4vD6NGjDY7FZK+4jY+Ph729val2R0REZFrVPEGvZ8+e6Nmz5yPbKBQKeHl5lbvt0qVL2LdvH06dOoV27doBAFauXIlevXrh448/ho+Pj96xGJzsBw4cqPNZCIGMjAycPn0as2bNMnR3RERE1eJJvPXu8OHD8PDwQM2aNfHiiy/iww8/RK1atQA8KKLd3Ny0iR4AgoODYWNjgxMnTmDAgAF6H8fgZO/q6qrz2cbGBgEBAYiKikJISIihuyMiIrIoubm5Op8VCgUUCoXB++nRowcGDhyIhg0bIjk5Ge+//z569uyJ+Ph42NraQqVSwcPDQ6ePnZ0d3N3doVKpDDqWQclerVZj+PDhaNmyJWrWrGnQgYiIiKyBr6+vzuc5c+Zg7ty5Bu9n8ODB2n+3bNkSrVq1QqNGjXD48GF0797d2DB1GJTsbW1tERISgkuXLjHZExGRZTHRNfu0tDQolUrt6spU9eXx9/dH7dq1ce3aNXTv3h1eXl64efOmTpuSkhJkZWVVeJ2/IgbPxm/RogX++OMPQ7sRERGZVek1e2MWAFAqlTqLqZL9n3/+idu3b8Pb2xsAEBQUhOzsbCQkJGjbHDp0CBqNBh06dDBo3wYn+w8//BCTJ0/G7t27kZGRgdzcXJ2FiIiIgLy8PCQmJiIxMREAkJKSgsTERKSmpiIvLw9TpkzBr7/+iuvXr+PgwYPo168fGjdujNDQUABA8+bN0aNHD4waNQonT57EL7/8grFjx2Lw4MEGzcQHDBjGj4qKwqRJk9CrVy8AwMsvv6zz2FwhBGQyGdRqtUEBEBERVZtqfAre6dOn0a1bN+3nyMhIAEBYWBjWrl2Ls2fPYuPGjcjOzoaPjw9CQkIwf/58nZGCLVu2YOzYsejevTtsbGwwaNAgrFixwuBY9E728+bNwzvvvIOff/7Z4IMQERGZXTXfZ9+1a1cIUXGn/fv3P3Yf7u7u2Lp1q2EHLofeyb404C5duhh9UCIiIqo+Bs3Gf9Tb7oiIiJ5kT+JDdaqLQcm+adOmj034WVlZRgVERERUJfg+e/3MmzevzBP0iIiI6MlmULIfPHhwmUf3ERERWQIO4+uB1+uJiMiiSXgYX++H6jzq9gEiIiJ6culd2Ws0mqqMg4iIqGpJuLI3+BW3RERElojX7ImIiKydhCt7g1+EQ0RERJaFlT0REUmDhCt7JnsiIpIEKV+z5zA+ERGRlWNlT0RE0sBhfCIiIuvGYXwiIiKyWqzsiYhIGjiMT0REZOUknOw5jE9ERGTlWNkTEZEkyP63GNPfUjHZExGRNEh4GJ/JnoiIJIG33hEREZHVYmVPRETSwGF8IiIiCbDghG0MDuMTERFZOVb2REQkCVKeoMdkT0RE0iDha/YcxiciIrJyrOyJiEgSOIxPRERk7TiMT0RERNaKlT0REUkCh/GJiIisnYSH8ZnsiYhIGiSc7HnNnoiIyMqxsiciIkngNXsiIiJrx2F8IiIislas7ImISBJkQkAmKl+eG9PX3JjsiYhIGjiMT0RERNaKlT0REUkCZ+MTERFZOw7jExERkbVisiciIkkoHcY3ZjFEXFwc+vbtCx8fH8hkMuzcuVNnuxACs2fPhre3NxwcHBAcHIyrV6/qtMnKysLQoUOhVCrh5uaGESNGIC8vz+BzZ7InIiJpECZYDJCfn4/WrVtj9erV5W5fvHgxVqxYgejoaJw4cQJOTk4IDQ1FQUGBts3QoUNx4cIFxMbGYvfu3YiLi8Po0aMNCwS8Zk9ERBJR3RP0evbsiZ49e5a7TQiBZcuWYebMmejXrx8AYNOmTfD09MTOnTsxePBgXLp0Cfv27cOpU6fQrl07AMDKlSvRq1cvfPzxx/Dx8dE7Flb2RERE1SwlJQUqlQrBwcHada6urujQoQPi4+MBAPHx8XBzc9MmegAIDg6GjY0NTpw4YdDxWNkTEZE0mGg2fm5urs5qhUIBhUJh0K5UKhUAwNPTU2e9p6endptKpYKHh4fOdjs7O7i7u2vb6IuVPRERSYYpJuf5+vrC1dVVuyxatMh8J6QnVvZEREQGSEtLg1Kp1H42tKoHAC8vLwBAZmYmvL29teszMzPRpk0bbZubN2/q9CspKUFWVpa2v75Y2RMRkTQIYfwCQKlU6iyVSfYNGzaEl5cXDh48qF2Xm5uLEydOICgoCAAQFBSE7OxsJCQkaNscOnQIGo0GHTp0MOh4rOyJiEgSqns2fl5eHq5du6b9nJKSgsTERLi7u6N+/fqYMGECPvzwQzRp0gQNGzbErFmz4OPjg/79+wMAmjdvjh49emDUqFGIjo5GcXExxo4di8GDBxs0Ex9gsiciIqoSp0+fRrdu3bSfIyMjAQBhYWGIiYnB1KlTkZ+fj9GjRyM7OxsvvPAC9u3bB3t7e22fLVu2YOzYsejevTtsbGwwaNAgrFixwuBYmOyJiEgaqvnZ+F27doUQFXeSyWSIiopCVFRUhW3c3d2xdetWww5cDiZ7IiKSBJnmwWJMf0vFCXpERERWjpU9lauWez5GDv0N7Z/+CwpFCdJVLvh4dUdc/aN2mbbvjYpHn5ArWLuhPXbsCTRDtETG2XjiIrx8i8us/yGmFla/X88MEVGVkPArbs2a7OPi4rBkyRIkJCQgIyMDO3bs0M5CJPNxdirE0vl78fsFL3ywsDtycu1R1ysXefnyMm07PnsDzZvewt9ZDmaIlMg03uvZFDa2//wmb9CsAB999QeO7nIzX1BkctU9G/9JYtZh/Me9EYjM49X+53HrthP+s+YFJF2rA9VNFyScrYuMTKVOu1ru+Xj3rZP4aHknlJTwihBZrpwsO9y5VUO7dAjORXqKHGfjncwdGpmSie6zt0Rmrewf9UYgMp+gdmlISPTBzMjDaBWYib+zHLFrfwD2HmyqbSOTCUwbdwzbf3gKN/6sacZoiUzLroYGLw66g+8+rQNAZu5wiEzCoq7ZFxYWorCwUPv53y8jINPw9riLPiFJ+Hb3U/jyu5YIaHwb7751EiUlNog90hgA8Fq/81CrZdi5p7mZoyUyred75MJZqcZPX7ubOxQyMQ7jW4hFixbpvHzA19fX3CFZJZkNcDWlFjZ8+QySr9fCngNNsfdAE/QOuQIAaOJ/G/17X8SS1S+AlQ9Zm9Aht3HqZyWyMmuYOxQyNWGCxUJZVLKfMWMGcnJytEtaWpq5Q7JKWXcckPqnm8661L9c4VE7DwDQolkm3JQF2LL2G+zdtgl7t22Cl0c+RoedxqbV35ghYiLT8KhbhKc75WHfVlb1ZF0sahi/Mu8MJsNdSPJAPZ8cnXX1vHORecsZAHAgzh9nznnrbF84MxYH4hrhp58bV1ucRKYWMjgL2X/b4cQB5eMbk8XhMD7RQ77bHYjmTW5h8ICz8PHKRbcX/kCv4KvYta8ZAOBunj2up9XUWUpKbHDnjgP+THc1c/RElSOTCYS8loUD22tCo+blKavE2fjm8bg3ApF5XEmujXlLuuGtob/hjVd+h+qmC9bGtMehY/7mDo2oyjzdOQ+e9Yqxf1stc4dCZHJmTfaPeyMQmc+J33xx4jf9J0AOi3ilCqMhqnq/HXFBqE9rc4dBVUjKw/hmTfaPeyMQERGRyUj4cbm8Zk9ERGTlLGo2PhERUWVxGJ+IiMjaacSDxZj+ForJnoiIpIHX7ImIiMhasbInIiJJkMHIa/Ymi6T6MdkTEZE0GPsUPAu+VZzD+ERERFaOlT0REUkCb70jIiKydpyNT0RERNaKlT0REUmCTAjIjJhkZ0xfc2OyJyIiadD8bzGmv4XiMD4REZGVY2VPRESSwGF8IiIiayfh2fhM9kREJA18gh4RERFZK1b2REQkCXyCHhERkbXjMD4RERFZK1b2REQkCTLNg8WY/paKyZ6IiKSBw/hERERkrVjZExGRNPChOkRERNZNyo/L5TA+ERGRlWNlT0RE0iDhCXpM9kREJA0Cxr2T3nJzPZM9ERFJA6/ZExERkdViZU9ERNIgYOQ1e5NFUu1Y2RMRkTSUTtAzZjHA3LlzIZPJdJZmzZpptxcUFCAiIgK1atWCs7MzBg0ahMzMTFOfNQAmeyIioirz1FNPISMjQ7scO3ZMu23ixInYtWsXtm/fjiNHjiA9PR0DBw6skjg4jE9ERNKgASAzsr+B7Ozs4OXlVWZ9Tk4O1q9fj61bt+LFF18EAGzYsAHNmzfHr7/+iueee86IQMtiZU9ERJJQOhvfmMVQV69ehY+PD/z9/TF06FCkpqYCABISElBcXIzg4GBt22bNmqF+/fqIj4832TmXYmVPRERkgNzcXJ3PCoUCCoWiTLsOHTogJiYGAQEByMjIwLx589CpUyecP38eKpUKcrkcbm5uOn08PT2hUqlMHjOTPRERSYOJnqDn6+urs3rOnDmYO3dumeY9e/bU/rtVq1bo0KED/Pz88PXXX8PBwaHycVQCkz0REUmDiZJ9WloalEqldnV5VX153Nzc0LRpU1y7dg0vvfQSioqKkJ2drVPdZ2ZmlnuN31i8Zk9ERGQApVKps+ib7PPy8pCcnAxvb2+0bdsWNWrUwMGDB7Xbk5KSkJqaiqCgIJPHzMqeiIikoZpfhDN58mT07dsXfn5+SE9Px5w5c2Bra4shQ4bA1dUVI0aMQGRkJNzd3aFUKjFu3DgEBQWZfCY+wGRPRERSUc233v35558YMmQIbt++jTp16uCFF17Ar7/+ijp16gAAli5dChsbGwwaNAiFhYUIDQ3FmjVrjAiwYkz2REQkCdX9Ipxt27Y9cru9vT1Wr16N1atXVzomffGaPRERkZVjZU9ERNJQzdfsnyRM9kREJA0aAciMSNgay032HMYnIiKycqzsiYhIGjiMT0REZO2MTPaw3GTPYXwiIiIrx8qeiIikgcP4REREVk4jYNRQPGfjExER0ZOKlT0REUmD0DxYjOlvoZjsiYhIGnjNnoiIyMrxmj0RERFZK1b2REQkDRzGJyIisnICRiZ7k0VS7TiMT0REZOVY2RMRkTRwGJ+IiMjKaTQAjLhXXmO599lzGJ+IiMjKsbInIiJp4DA+ERGRlZNwsucwPhERkZVjZU9ERNIg4cflMtkTEZEkCKGBMOLNdcb0NTcmeyIikgYhjKvOec2eiIiInlSs7ImISBqEkdfsLbiyZ7InIiJp0GgAmRHX3S34mj2H8YmIiKwcK3siIpIGDuMTERFZN6HRQBgxjG/Jt95xGJ+IiMjKsbInIiJp4DA+ERGRldMIQCbNZM9hfCIiIivHyp6IiKRBCADG3GdvuZU9kz0REUmC0AgII4bxBZM9ERHRE05oYFxlz1vviIiI6AnFyp6IiCSBw/hERETWTsLD+Bad7Ev/yiopKTRzJERVRyaKzR0CUZUpwYOf7+qomktQbNQzdUpjtUQWnezv3r0LAPjl9BIzR0JERMa4e/cuXF1dq2TfcrkcXl5eOKbaY/S+vLy8IJfLTRBV9ZIJC74IodFokJ6eDhcXF8hkMnOHIwm5ubnw9fVFWloalEqlucMhMin+fFc/IQTu3r0LHx8f2NhU3ZzxgoICFBUVGb0fuVwOe3t7E0RUvSy6srexsUG9evXMHYYkKZVK/jIkq8Wf7+pVVRX9w+zt7S0ySZsKb70jIiKyckz2REREVo7JngyiUCgwZ84cKBQKc4dCZHL8+SZrZdET9IiIiOjxWNkTERFZOSZ7IiIiK8dkT0REZOWY7ImIiKwckz3pbfXq1WjQoAHs7e3RoUMHnDx50twhEZlEXFwc+vbtCx8fH8hkMuzcudPcIRGZFJM96eWrr75CZGQk5syZg99++w2tW7dGaGgobt68ae7QiIyWn5+P1q1bY/Xq1eYOhahK8NY70kuHDh3Qvn17rFq1CsCD9xL4+vpi3LhxmD59upmjIzIdmUyGHTt2oH///uYOhchkWNnTYxUVFSEhIQHBwcHadTY2NggODkZ8fLwZIyMiIn0w2dNj/f3331Cr1fD09NRZ7+npCZVKZaaoiIhIX0z2REREVo7Jnh6rdu3asLW1RWZmps76zMxMeHl5mSkqIiLSF5M9PZZcLkfbtm1x8OBB7TqNRoODBw8iKCjIjJEREZE+7MwdAFmGyMhIhIWFoV27dnj22WexbNky5OfnY/jw4eYOjchoeXl5uHbtmvZzSkoKEhMT4e7ujvr165sxMiLT4K13pLdVq1ZhyZIlUKlUaNOmDVasWIEOHTqYOywiox0+fBjdunUrsz4sLAwxMTHVHxCRiTHZExERWTlesyciIrJyTPZERERWjsmeiIjIyjHZExERWTkmeyIiIivHZE9ERGTlmOyJiIisHJM9kZHCw8N13n3etWtXTJgwodrjOHz4MGQyGbKzsytsI5PJsHPnTr33OXfuXLRp08aouK5fvw6ZTIbExESj9kNElcdkT1YpPDwcMpkMMpkMcrkcjRs3RlRUFEpKSqr82N999x3mz5+vV1t9EjQRkbH4bHyyWj169MCGDRtQWFiIPXv2ICIiAjVq1MCMGTPKtC0qKoJcLjfJcd3d3U2yHyIiU2FlT1ZLoVDAy8sLfn5+GDNmDIKDg/HDDz8A+GfofcGCBfDx8UFAQAAAIC0tDa+++irc3Nzg7u6Ofv364fr169p9qtVqREZGws3NDbVq1cLUqVPx7ydO/3sYv7CwENOmTYOvry8UCgUaN26M9evX4/r169rnsdesWRMymQzh4eEAHrxVcNGiRWjYsCEcHBzQunVrfPPNNzrH2bNnD5o2bQoHBwd069ZNJ059TZs2DU2bNoWjoyP8/f0xa9YsFBcXl2n36aefwtfXF46Ojnj11VeRk5Ojs33dunVo3rw57O3t0axZM6xZs8bgWIio6jDZk2Q4ODigqKhI+/ngwYNISkpCbGwsdu/ejeLiYoSGhsLFxQVHjx7FL7/8AmdnZ/To0UPb7z//+Q9iYmLwxRdf4NixY8jKysKOHTseedxhw4bhyy+/xIoVK3Dp0iV8+umncHZ2hq+vL7799lsAQFJSEjIyMrB8+XIAwKJFi7Bp0yZER0fjwoULmDhxIt544w0cOXIEwIM/SgYOHIi+ffsiMTERI0eOxPTp0w3+TlxcXBATE4OLFy9i+fLl+Pzzz7F06VKdNteuXcPXX3+NXbt2Yd++fThz5gzeffdd7fYtW7Zg9uzZWLBgAS5duoSFCxdi1qxZ2Lhxo8HxEFEVEURWKCwsTPTr108IIYRGoxGxsbFCoVCIyZMna7d7enqKwsJCbZ/NmzeLgIAAodFotOsKCwuFg4OD2L9/vxBCCG9vb7F48WLt9uLiYlGvXj3tsYQQokuXLmL8+PFCCCGSkpIEABEbG1tunD///LMAIO7cuaNdV1BQIBwdHcXx48d12o4YMUIMGTJECCHEjBkzRGBgoM72adOmldnXvwEQO3bsqHD7kiVLRNu2bbWf58yZI2xtbcWff/6pXbd3715hY2MjMjIyhBBCNGrUSGzdulVnP/PnzxdBQUFCCCFSUlIEAHHmzJkKj0tEVYvX7Mlq7d69G87OziguLoZGo8Hrr7+OuXPnare3bNlS5zr977//jmvXrsHFxUVnPwUFBUhOTkZOTg4yMjJ0XutrZ2eHdu3alRnKL5WYmAhbW1t06dJF77ivXbuGe/fu4aWXXtJZX1RUhKeffhoAcOnSpTKvFw4KCtL7GKW++uorrFixAsnJycjLy0NJSQmUSqVOm/r166Nu3bo6x9FoNEhKSoKLiwuSk5MxYsQIjBo1StumpKQErq6uBsdDRFWDyZ6sVrdu3bB27VrI5XL4+PjAzk73x93JyUnnc15eHtq2bYstW7aU2VedOnUqFYODg4PBffLy8gAAP/74o06SBR7MQzCV+Ph4DB06FPPmzUNoaChcXV2xbds2/Oc//zE41s8//7zMHx+2trYmi5WIjMNkT1bLyckJjRs31rv9M888g6+++goeHh5lqttS3t7eOHHiBDp37gzgQQWbkJCAZ555ptz2LVu2hEajwZEjRxAcHFxme+nIglqt1q4LDAyEQqFAampqhSMCzZs31042LPXrr78+/iQfcvz4cfj5+eGDDz7Qrrtx40aZdqmpqUhPT4ePj4/2ODY2NggICICnpyd8fHzwxx9/YOjQoQYdn4iqDyfoEf3P0KFDUbt2bfTr1w9Hjx5FSkoKDh8+jPfeew9//vknAGD8+PH46KOPsHPnTly+fBnvvvvuI++Rb9CgAcLCwvDWW29h586d2n1+/fXXAAA/Pz/IZDLs3r0bt27dQl5eHlxcXDB58mRMnDgRGzduRHJyMn777TesXLlSO+ntnXfewdWrVzFlyhQkJSVh69atiImJMeh8mzRpgtTUVGzbtg3JyclYsWJFuZMN7e3tERYWht9//x1Hjx7Fe++9h1dffRVeXl4AgHnz5mHRokVYsWIFrly5gnPnzmHDhg345JNPDIqHiKoOkz3R/zg6OiIuLg7169fHwIED0bx5c4wYMQIFBQXaSn/SpEl48803ERYWhqCgILi4uGDAgAGP3O/atWvxyiuv4N1330WzZs0watQo5OfnAwDq1q2LefPmYfr06fD09MTYsWMBAPPnz8esWbOwaNEiNG/eHD169MCPP/6Ihg0bAnhwHf3bb7/Fzp070bp1a0RHR2PhwoUGne/LL7+MiRMnYuzYsWjTpg2OHz+OWbNmlWnXuHFjDBw4EL169UJISAhatWqlc2vdyJEjsW7dOmzYsAEtW7ZEly5dEBMTo42ViMxPJiqaWURERERWgZU9ERGRlWOyJyIisnJM9kRERFaOyZ6IiMjKMdkTERFZOSZ7IiIiK8dkT0REZOWY7ImIiKwckz0REZGVY7InIiKyckz2REREVo7JnoiIyMr9fwEFvF7MpM/sAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#############################\n",
    "# 6) TRAIN 3 MODELS & EVALUATE\n",
    "#############################\n",
    "\n",
    "# models_to_run = ['random_forest', 'logistic', 'svm', 'xgboost']\n",
    "models_to_run = ['xgboost']\n",
    "trained_models = {}\n",
    "\n",
    "for model_name in models_to_run:\n",
    "    print(\"\\n=======================================\")\n",
    "    print(f\"Training Model: {model_name.upper()}\")\n",
    "    \n",
    "    # Create the group vector for training (subject IDs corresponding to each electrode)\n",
    "    train_groups = combined_df[train_mask]['subject_id'].values\n",
    "    \n",
    "    # Train the model using group-aware cross-validation\n",
    "    clf = train_and_evaluate_with_groups(X_train_scaled, y_train, groups=train_groups, model_choice=model_name)\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    y_pred_test = clf.predict(X_test_scaled)\n",
    "    print(f\"\\n--- {model_name.upper()} TEST SET PERFORMANCE ---\")\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred_test))\n",
    "    if hasattr(clf, 'predict_proba'):\n",
    "        y_proba_test = clf.predict_proba(X_test_scaled)[:, 1]\n",
    "        print(\"ROC AUC:\", roc_auc_score(y_test, y_proba_test))\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred_test))\n",
    "    \n",
    "    # Display confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred_test)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "    disp.plot(values_format='d')\n",
    "    plt.title(f\"Confusion Matrix - {model_name.upper()}\")\n",
    "    plt.show()\n",
    "    \n",
    "    trained_models[model_name] = clf\n",
    "\n",
    "# for model_name in models_to_run:\n",
    "#     print(\"\\n=======================================\")\n",
    "#     print(f\"Training Model: {model_name.upper()}\")\n",
    "#     clf = train_and_evaluate(X_train_scaled, y_train, model_choice=model_name)\n",
    "    \n",
    "#     # Evaluate on test set\n",
    "#     y_pred_test = clf.predict(X_test_scaled)\n",
    "#     print(f\"\\n--- {model_name.upper()} TEST SET PERFORMANCE ---\")\n",
    "#     print(\"Accuracy:\", accuracy_score(y_test, y_pred_test))\n",
    "#     if hasattr(clf, 'predict_proba'):\n",
    "#         y_proba_test = clf.predict_proba(X_test_scaled)[:, 1]\n",
    "#         print(\"ROC AUC:\", roc_auc_score(y_test, y_proba_test))\n",
    "#     print(\"\\nClassification Report:\")\n",
    "#     print(classification_report(y_test, y_pred_test))\n",
    "    \n",
    "#     # Display confusion matrix\n",
    "#     cm = confusion_matrix(y_test, y_pred_test)\n",
    "#     disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "#     disp.plot(values_format='d')\n",
    "#     plt.title(f\"Confusion Matrix - {model_name.upper()}\")\n",
    "#     plt.show()\n",
    "    \n",
    "#     trained_models[model_name] = clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== FEATURE IMPORTANCE ASSESSMENT ===\n"
     ]
    }
   ],
   "source": [
    "#############################\n",
    "# 7) FEATURE IMPORTANCE ASSESSMENT\n",
    "#############################\n",
    "\n",
    "print(\"\\n=== FEATURE IMPORTANCE ASSESSMENT ===\")\n",
    "\n",
    "# (a) Random Forest built-in importances\n",
    "rf_model = trained_models.get('random_forest')\n",
    "if rf_model is not None and hasattr(rf_model, 'feature_importances_'):\n",
    "    importances = rf_model.feature_importances_\n",
    "    sorted_idx = np.argsort(importances)[::-1]\n",
    "    sorted_features = [present_features[i] for i in sorted_idx]\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.bar(range(len(importances)), importances[sorted_idx], align='center')\n",
    "    plt.xticks(range(len(importances)), sorted_features, rotation=90)\n",
    "    plt.title(\"Random Forest Feature Importances\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    print(\"Top 10 RF Features:\")\n",
    "    for i in range(min(10, len(sorted_features))):\n",
    "        print(f\"{i+1}. {sorted_features[i]} (importance={importances[sorted_idx][i]:.4f})\")\n",
    "\n",
    "# (b) Permutation Importance for Logistic Regression\n",
    "lr_model = trained_models.get('logistic')\n",
    "if lr_model is not None:\n",
    "    print(\"\\nPermutation Importance for Logistic Regression (Test Set):\")\n",
    "    result = permutation_importance(\n",
    "        lr_model, X_test_scaled, y_test, n_repeats=20, random_state=42, scoring='roc_auc'\n",
    "    )\n",
    "    perm_importances = result.importances_mean\n",
    "    sorted_idx = np.argsort(perm_importances)[::-1]\n",
    "    sorted_features = [present_features[i] for i in sorted_idx]\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.bar(range(len(perm_importances)), perm_importances[sorted_idx], align='center')\n",
    "    plt.xticks(range(len(perm_importances)), sorted_features, rotation=90)\n",
    "    plt.title(\"Permutation Importance (Logistic Regression)\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# (c) Permutation Importance for SVM (since SHAP is avoided)\n",
    "svm_model = trained_models.get('svm')\n",
    "if svm_model is not None:\n",
    "    print(\"\\nPermutation Importance for SVM (Test Set):\")\n",
    "    result = permutation_importance(\n",
    "        svm_model, X_test_scaled, y_test, n_repeats=20, random_state=42, scoring='roc_auc'\n",
    "    )\n",
    "    perm_importances = result.importances_mean\n",
    "    sorted_idx = np.argsort(perm_importances)[::-1]\n",
    "    sorted_features = [present_features[i] for i in sorted_idx]\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.bar(range(len(perm_importances)), perm_importances[sorted_idx], align='center')\n",
    "    plt.xticks(range(len(perm_importances)), sorted_features, rotation=90)\n",
    "    plt.title(\"Permutation Importance (SVM)\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Detailed Summary of Model Results on Test Set ===\n",
      "\n",
      "------------------------------\n",
      "Model: XGBOOST\n",
      "Accuracy: 0.797\n",
      "ROC AUC: 0.5818537286039183\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.94      0.89       353\n",
      "           1       0.24      0.10      0.14        71\n",
      "\n",
      "    accuracy                           0.80       424\n",
      "   macro avg       0.54      0.52      0.51       424\n",
      "weighted avg       0.74      0.80      0.76       424\n",
      "\n",
      "Confusion Matrix:\n",
      "[[331  22]\n",
      " [ 64   7]]\n"
     ]
    }
   ],
   "source": [
    "# %% [code]\n",
    "print(\"=== Detailed Summary of Model Results on Test Set ===\")\n",
    "\n",
    "# Loop over each trained model and compute metrics\n",
    "for model_name in models_to_run:\n",
    "    print(\"\\n------------------------------\")\n",
    "    print(f\"Model: {model_name.upper()}\")\n",
    "    \n",
    "    model = trained_models[model_name]\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    \n",
    "    # Compute ROC AUC if the model supports predict_proba\n",
    "    if hasattr(model, 'predict_proba'):\n",
    "        y_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_test, y_proba)\n",
    "    else:\n",
    "        roc_auc = \"N/A\"\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    # Print metrics and classification report; set zero_division=0 to avoid warnings\n",
    "    print(\"Accuracy: {:.3f}\".format(accuracy))\n",
    "    print(\"ROC AUC: {}\".format(roc_auc))\n",
    "    clf_report = classification_report(y_test, y_pred, zero_division=0)\n",
    "    print(\"Classification Report:\")\n",
    "    print(clf_report)\n",
    "    \n",
    "    # Display the confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)\n",
    "    \n",
    "    # disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "    # disp.plot(values_format='d')\n",
    "    # plt.title(f\"Confusion Matrix - {model_name.upper()}\")\n",
    "    # plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cnt_gen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
