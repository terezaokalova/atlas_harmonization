{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "import joblib \n",
    "import dill \n",
    "\n",
    "# signals\n",
    "import mne\n",
    "from scipy.signal import welch, get_window\n",
    "from scipy.signal.windows import hamming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path_data = '../Data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.26.4\n",
      "2.2.2\n"
     ]
    }
   ],
   "source": [
    "print(np.__version__)\n",
    "print(pd.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   snum   abvr                   roi         lobe  isSideLeft  roiNum  \\\n",
      "0     1  Tha_L  Left-Thalamus-Proper  Subcortical           1      10   \n",
      "1     2  Cau_L          Left-Caudate  Subcortical           1      11   \n",
      "2     3  Put_L          Left-Putamen  Subcortical           1      12   \n",
      "3     4  Pal_L         Left-Pallidum  Subcortical           1      13   \n",
      "4     5  Hip_L      Left-Hippocampus  Subcortical           1      17   \n",
      "\n",
      "     cmap_R    cmap_G    cmap_B  \n",
      "0  0.000000  0.462745  0.054902  \n",
      "1  0.478431  0.729412  0.862745  \n",
      "2  0.925490  0.050980  0.690196  \n",
      "3  0.047059  0.188235  1.000000  \n",
      "4  0.862745  0.847059  0.078431  \n"
     ]
    }
   ],
   "source": [
    "dk_atlas_df = pd.read_csv(os.path.join(base_path_data, 'desikanKilliany.csv'))\n",
    "print(dk_atlas_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "empty_like method already has a different docstring",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Load the pickle file\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(base_path_data, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhup_df.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m----> 6\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Update the docstring for the 'empty_like' method\u001b[39;00m\n\u001b[1;32m      9\u001b[0m pd\u001b[38;5;241m.\u001b[39mcore\u001b[38;5;241m.\u001b[39mframe\u001b[38;5;241m.\u001b[39mDataFrame\u001b[38;5;241m.\u001b[39mempty_like\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__doc__\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUpdated docstring\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/cnt_gen/lib/python3.12/site-packages/numpy/_core/numeric.py:11\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmath\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m multiarray\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m numerictypes \u001b[38;5;28;01mas\u001b[39;00m nt\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmultiarray\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     14\u001b[0m     ALLOW_THREADS, BUFSIZE, CLIP, MAXDIMS, MAY_SHARE_BOUNDS, MAY_SHARE_EXACT,\n\u001b[1;32m     15\u001b[0m     RAISE, WRAP, arange, array, asarray, asanyarray, ascontiguousarray,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     21\u001b[0m     _get_promotion_state, _set_promotion_state, vecdot\n\u001b[1;32m     22\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/cnt_gen/lib/python3.12/site-packages/numpy/_core/multiarray.py:82\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;66;03m# We can't verify dispatcher signatures because NumPy's C functions don't\u001b[39;00m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;66;03m# support introspection.\u001b[39;00m\n\u001b[1;32m     77\u001b[0m array_function_from_c_func_and_dispatcher \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(\n\u001b[1;32m     78\u001b[0m     overrides\u001b[38;5;241m.\u001b[39marray_function_from_dispatcher,\n\u001b[1;32m     79\u001b[0m     module\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m'\u001b[39m, docs_from_dispatcher\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, verify\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m---> 82\u001b[0m \u001b[38;5;129;43m@array_function_from_c_func_and_dispatcher\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_multiarray_umath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mempty_like\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;43;01mdef\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;21;43mempty_like\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprototype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[1;32m     85\u001b[0m \u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;250;43m    \u001b[39;49m\u001b[38;5;124;43;03m\"\"\"\u001b[39;49;00m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;124;43;03m    empty_like(prototype, dtype=None, order='K', subok=True, shape=None, *,\u001b[39;49;00m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;124;43;03m               device=None)\u001b[39;49;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    156\u001b[0m \n\u001b[1;32m    157\u001b[0m \u001b[38;5;124;43;03m    \"\"\"\u001b[39;49;00m\u001b[43m   \u001b[49m\u001b[38;5;66;43;03m# NOQA\u001b[39;49;00m\n\u001b[1;32m    158\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mreturn\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mprototype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/cnt_gen/lib/python3.12/site-packages/numpy/_core/overrides.py:178\u001b[0m, in \u001b[0;36marray_function_from_dispatcher.<locals>.decorator\u001b[0;34m(dispatcher)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorator\u001b[39m(dispatcher):\n\u001b[0;32m--> 178\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marray_function_dispatch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdispatcher\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverify\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdocs_from_dispatcher\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdocs_from_dispatcher\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimplementation\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/cnt_gen/lib/python3.12/site-packages/numpy/_core/overrides.py:158\u001b[0m, in \u001b[0;36marray_function_dispatch.<locals>.decorator\u001b[0;34m(implementation)\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    153\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__array_function__ expects `like=` to be the last \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    154\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124margument and a keyword-only argument. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    155\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimplementation\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not seem to comply.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m docs_from_dispatcher:\n\u001b[0;32m--> 158\u001b[0m     \u001b[43madd_docstring\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimplementation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdispatcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__doc__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    160\u001b[0m public_api \u001b[38;5;241m=\u001b[39m _ArrayFunctionDispatcher(dispatcher, implementation)\n\u001b[1;32m    161\u001b[0m public_api \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mwraps(implementation)(public_api)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: empty_like method already has a different docstring"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "# Load the pickle file\n",
    "with open(os.path.join(base_path_data, 'hup_df.pkl'), 'rb') as f:\n",
    "    df = pickle.load(f)\n",
    "\n",
    "# Update the docstring for the 'empty_like' method\n",
    "pd.core.frame.DataFrame.empty_like.__doc__ = \"Updated docstring\"\n",
    "\n",
    "# Now try to use the dataframe\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "empty_like method already has a different docstring",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpickle\u001b[39;00m \n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(base_path_data, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhup_df.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f: hup_df \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(f, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatin1\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/cnt_gen/lib/python3.12/site-packages/numpy/_core/numeric.py:11\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmath\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m multiarray\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m numerictypes \u001b[38;5;28;01mas\u001b[39;00m nt\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmultiarray\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     14\u001b[0m     ALLOW_THREADS, BUFSIZE, CLIP, MAXDIMS, MAY_SHARE_BOUNDS, MAY_SHARE_EXACT,\n\u001b[1;32m     15\u001b[0m     RAISE, WRAP, arange, array, asarray, asanyarray, ascontiguousarray,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     21\u001b[0m     _get_promotion_state, _set_promotion_state, vecdot\n\u001b[1;32m     22\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/cnt_gen/lib/python3.12/site-packages/numpy/_core/multiarray.py:82\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;66;03m# We can't verify dispatcher signatures because NumPy's C functions don't\u001b[39;00m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;66;03m# support introspection.\u001b[39;00m\n\u001b[1;32m     77\u001b[0m array_function_from_c_func_and_dispatcher \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(\n\u001b[1;32m     78\u001b[0m     overrides\u001b[38;5;241m.\u001b[39marray_function_from_dispatcher,\n\u001b[1;32m     79\u001b[0m     module\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m'\u001b[39m, docs_from_dispatcher\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, verify\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m---> 82\u001b[0m \u001b[38;5;129;43m@array_function_from_c_func_and_dispatcher\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_multiarray_umath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mempty_like\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;43;01mdef\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;21;43mempty_like\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprototype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[1;32m     85\u001b[0m \u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;250;43m    \u001b[39;49m\u001b[38;5;124;43;03m\"\"\"\u001b[39;49;00m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;124;43;03m    empty_like(prototype, dtype=None, order='K', subok=True, shape=None, *,\u001b[39;49;00m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;124;43;03m               device=None)\u001b[39;49;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    156\u001b[0m \n\u001b[1;32m    157\u001b[0m \u001b[38;5;124;43;03m    \"\"\"\u001b[39;49;00m\u001b[43m   \u001b[49m\u001b[38;5;66;43;03m# NOQA\u001b[39;49;00m\n\u001b[1;32m    158\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mreturn\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mprototype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/cnt_gen/lib/python3.12/site-packages/numpy/_core/overrides.py:178\u001b[0m, in \u001b[0;36marray_function_from_dispatcher.<locals>.decorator\u001b[0;34m(dispatcher)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorator\u001b[39m(dispatcher):\n\u001b[0;32m--> 178\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marray_function_dispatch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdispatcher\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverify\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdocs_from_dispatcher\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdocs_from_dispatcher\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimplementation\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/cnt_gen/lib/python3.12/site-packages/numpy/_core/overrides.py:158\u001b[0m, in \u001b[0;36marray_function_dispatch.<locals>.decorator\u001b[0;34m(implementation)\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    153\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__array_function__ expects `like=` to be the last \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    154\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124margument and a keyword-only argument. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    155\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimplementation\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not seem to comply.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m docs_from_dispatcher:\n\u001b[0;32m--> 158\u001b[0m     \u001b[43madd_docstring\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimplementation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdispatcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__doc__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    160\u001b[0m public_api \u001b[38;5;241m=\u001b[39m _ArrayFunctionDispatcher(dispatcher, implementation)\n\u001b[1;32m    161\u001b[0m public_api \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mwraps(implementation)(public_api)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: empty_like method already has a different docstring"
     ]
    }
   ],
   "source": [
    "import pickle \n",
    "with open(os.path.join(base_path_data, 'hup_df.pkl'), 'rb') as f: hup_df = pickle.load(f, encoding='latin1')\n",
    "hup_df.to_csv(os.path.join(base_path_data, 'hup_df.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy._core.numeric'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/cnt_gen/lib/python3.12/site-packages/pandas/io/pickle.py:202\u001b[0m, in \u001b[0;36mread_pickle\u001b[0;34m(filepath_or_buffer, compression, storage_options)\u001b[0m\n\u001b[1;32m    201\u001b[0m         warnings\u001b[38;5;241m.\u001b[39msimplefilter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;167;01mWarning\u001b[39;00m)\n\u001b[0;32m--> 202\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandles\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m excs_to_catch:\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;66;03m# e.g.\u001b[39;00m\n\u001b[1;32m    205\u001b[0m     \u001b[38;5;66;03m#  \"No module named 'pandas.core.sparse.series'\"\u001b[39;00m\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;66;03m#  \"Can't get attribute '__nat_unpickle' on <module 'pandas._libs.tslib\"\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'numpy._core.numeric'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m base_path_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../Data\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 3\u001b[0m hup_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_pickle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_path_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhup_df.pkl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m mni_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_pickle(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(base_path_data, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmni_df.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[0;32m~/anaconda3/envs/cnt_gen/lib/python3.12/site-packages/pandas/io/pickle.py:207\u001b[0m, in \u001b[0;36mread_pickle\u001b[0;34m(filepath_or_buffer, compression, storage_options)\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mload(handles\u001b[38;5;241m.\u001b[39mhandle)\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m excs_to_catch:\n\u001b[1;32m    204\u001b[0m         \u001b[38;5;66;03m# e.g.\u001b[39;00m\n\u001b[1;32m    205\u001b[0m         \u001b[38;5;66;03m#  \"No module named 'pandas.core.sparse.series'\"\u001b[39;00m\n\u001b[1;32m    206\u001b[0m         \u001b[38;5;66;03m#  \"Can't get attribute '__nat_unpickle' on <module 'pandas._libs.tslib\"\u001b[39;00m\n\u001b[0;32m--> 207\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandles\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mUnicodeDecodeError\u001b[39;00m:\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;66;03m# e.g. can occur for files written in py27; see GH#28645 and GH#31988\u001b[39;00m\n\u001b[1;32m    210\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pc\u001b[38;5;241m.\u001b[39mload(handles\u001b[38;5;241m.\u001b[39mhandle, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlatin-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/cnt_gen/lib/python3.12/site-packages/pandas/compat/pickle_compat.py:231\u001b[0m, in \u001b[0;36mload\u001b[0;34m(fh, encoding, is_verbose)\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;66;03m# \"Unpickler\" has no attribute \"is_verbose\"  [attr-defined]\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     up\u001b[38;5;241m.\u001b[39mis_verbose \u001b[38;5;241m=\u001b[39m is_verbose  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m--> 231\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mup\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/cnt_gen/lib/python3.12/pickle.py:1205\u001b[0m, in \u001b[0;36m_Unpickler.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1203\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEOFError\u001b[39;00m\n\u001b[1;32m   1204\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, bytes_types)\n\u001b[0;32m-> 1205\u001b[0m         \u001b[43mdispatch\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1206\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _Stop \u001b[38;5;28;01mas\u001b[39;00m stopinst:\n\u001b[1;32m   1207\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m stopinst\u001b[38;5;241m.\u001b[39mvalue\n",
      "File \u001b[0;32m~/anaconda3/envs/cnt_gen/lib/python3.12/pickle.py:1530\u001b[0m, in \u001b[0;36m_Unpickler.load_stack_global\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1528\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(name) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mstr\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(module) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m   1529\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m UnpicklingError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSTACK_GLOBAL requires str\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1530\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/anaconda3/envs/cnt_gen/lib/python3.12/site-packages/pandas/compat/pickle_compat.py:162\u001b[0m, in \u001b[0;36mUnpickler.find_class\u001b[0;34m(self, module, name)\u001b[0m\n\u001b[1;32m    160\u001b[0m key \u001b[38;5;241m=\u001b[39m (module, name)\n\u001b[1;32m    161\u001b[0m module, name \u001b[38;5;241m=\u001b[39m _class_locations_map\u001b[38;5;241m.\u001b[39mget(key, key)\n\u001b[0;32m--> 162\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/cnt_gen/lib/python3.12/pickle.py:1572\u001b[0m, in \u001b[0;36m_Unpickler.find_class\u001b[0;34m(self, module, name)\u001b[0m\n\u001b[1;32m   1570\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m _compat_pickle\u001b[38;5;241m.\u001b[39mIMPORT_MAPPING:\n\u001b[1;32m   1571\u001b[0m         module \u001b[38;5;241m=\u001b[39m _compat_pickle\u001b[38;5;241m.\u001b[39mIMPORT_MAPPING[module]\n\u001b[0;32m-> 1572\u001b[0m \u001b[38;5;28;43m__import__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1573\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproto \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m:\n\u001b[1;32m   1574\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _getattribute(sys\u001b[38;5;241m.\u001b[39mmodules[module], name)[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'numpy._core.numeric'"
     ]
    }
   ],
   "source": [
    "base_path_data = '../Data'\n",
    "\n",
    "hup_df = pd.read_pickle(os.path.join(base_path_data, 'hup_df.pkl'))\n",
    "mni_df = pd.read_pickle(os.path.join(base_path_data, 'mni_df.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PREV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path_data = '../Data'\n",
    "hup_atlas = sio.loadmat(os.path.join(base_path_data, 'HUP_atlas.mat'))\n",
    "mni_atlas = sio.loadmat(os.path.join(base_path_data, 'MNI_atlas.mat'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "hup_df = pd.DataFrame(hup_atlas['mni_coords'], columns=['x', 'y', 'z'])\n",
    "mni_df = pd.DataFrame(mni_atlas['ChannelPosition'], columns=['x', 'y', 'z'])\n",
    "\n",
    "hup_ts = pd.DataFrame(hup_atlas['wake_clip']) # (12000, 3431) @ x-axis is time steps, y-axis is electrodes\n",
    "mni_ts = pd.DataFrame(mni_atlas['Data_W']) # (13600, 1765)  @ x-axis is time steps, y-axis is electrodes\n",
    "\n",
    "hup_patients = pd.DataFrame(hup_atlas['patient_no'])\n",
    "mni_patients = pd.DataFrame(mni_atlas['Patient'])\n",
    "\n",
    "hup_patient_ids = np.unique(hup_atlas['patient_no'])\n",
    "mni_patient_ids = np.unique(mni_atlas['Patient']) \n",
    "\n",
    "mni_samp_freq = int(mni_atlas['SamplingFrequency'].flatten()[~np.isnan(mni_atlas['SamplingFrequency'].flatten())][0])\n",
    "hup_samp_freq = int(hup_atlas['SamplingFrequency'].flatten()[~np.isnan(hup_atlas['SamplingFrequency'].flatten())][0])\n",
    "\n",
    "hup_patient_total_el_counts = len(hup_atlas['patient_no'])\n",
    "mni_patient_total_el_counts = len(mni_atlas['Patient'])\n",
    "\n",
    "hup_patient_numbers = hup_atlas['patient_no'].flatten()\n",
    "hup_el_to_pat_map_dict = {}\n",
    "for idx, patient_num in enumerate(hup_patient_numbers):\n",
    "    hup_el_to_pat_map_dict[idx] = patient_num\n",
    "hup_idx_map_arr = np.array([patient_num for patient_num in hup_patient_numbers]) # arr equivalent\n",
    "\n",
    "mni_patient_numbers = mni_atlas['Patient'].flatten()\n",
    "mni_el_to_pat_map_dict = {}\n",
    "for idx, patient_num in enumerate(mni_patient_numbers):\n",
    "    mni_el_to_pat_map_dict[idx] = patient_num\n",
    "mni_idx_map_arr = np.array([patient_num for patient_num in mni_patient_numbers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_norm_psd(iEEGnormal, data_timeS, sampling_frequency=200):\n",
    "    \"\"\"\n",
    "    Function to compute normalized power spectral densities for different EEG frequency bands.\n",
    "    \n",
    "    Args:\n",
    "    iEEGnormal (DataFrame): A DataFrame to append results to.\n",
    "    data_timeS (array): Time domain EEG data for a single electrode (1D array)\n",
    "    sampling_frequency (int): Sampling frequency of the EEG data.\n",
    "    \n",
    "    Returns:\n",
    "    DataFrame: Updated DataFrame with new EEG features.\n",
    "    \"\"\"\n",
    "    \n",
    "    Fs = sampling_frequency\n",
    "    window = Fs * 2\n",
    "    NFFT = window\n",
    "    \n",
    "    # Compute PSD\n",
    "    f, data_psd = welch(data_timeS, fs=Fs, window=hamming(window), \n",
    "                       nfft=NFFT, scaling='density', noverlap=window//2)\n",
    "    \n",
    "    # filter out noise frequency 57.5Hz to 62.5Hz\n",
    "    noise_mask = (f >= 57.5) & (f <= 62.5)\n",
    "    f = f[~noise_mask]\n",
    "    # Handle 1D data_psd\n",
    "    data_psd = data_psd[~noise_mask]\n",
    "    \n",
    "    def bandpower(psd, freqs, freq_range):\n",
    "        \"\"\"Calculate power in the given frequency range.\"\"\"\n",
    "        idx = np.logical_and(freqs >= freq_range[0], freqs <= freq_range[1])\n",
    "        return np.trapz(psd[idx], freqs[idx])\n",
    "    \n",
    "    # Define frequency bands\n",
    "    bands = {'delta': (1, 4), 'theta': (4, 8), 'alpha': (8, 13), \n",
    "             'beta': (13, 30), 'gamma': (30, 80), 'broad': (1, 80)}\n",
    "    \n",
    "    # Calculate band powers (using 1D data_psd)\n",
    "    band_powers = {band: bandpower(data_psd, f, freq_range) \n",
    "                  for band, freq_range in bands.items()}\n",
    "    \n",
    "    # Compute log transform\n",
    "    log_band_powers = {f'{band}log': np.log10(power + 1) \n",
    "                      for band, power in band_powers.items()}\n",
    "    \n",
    "    # Calculate total power\n",
    "    total_band_power = np.sum([value for value in log_band_powers.values()])\n",
    "    \n",
    "    # Calculate relative powers\n",
    "    relative_band_powers = {f'{band}Rel': log_band_powers[f'{band}log'] / total_band_power \n",
    "                          for band in bands}\n",
    "    \n",
    "    # Create DataFrame row\n",
    "    data_to_append = pd.DataFrame([relative_band_powers])\n",
    "    data_to_append['broadlog'] = log_band_powers['broadlog']\n",
    "    \n",
    "    # Append to existing DataFrame\n",
    "    iEEGnormal = pd.concat([iEEGnormal, data_to_append], ignore_index=True)\n",
    "    \n",
    "    return iEEGnormal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For HUP data:\n",
    "Processed from patient 1 to patient 60\n",
    "Last processed electrode is 3430\n",
    "Each electrode's time series has shape (12000,)\n",
    "\n",
    "\n",
    "For MNI data:\n",
    "Processed from patient 1 to patient 110\n",
    "Last processed electrode is 1764\n",
    "Each electrode's time series has shape (13600,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "hup_iEEGnormal = pd.DataFrame()\n",
    "mni_iEEGnormal = pd.DataFrame()\n",
    "\n",
    "# for each patient, for each electrode, compute PSD\n",
    "for patient in hup_patient_ids:\n",
    "    # print(f\"Processing HUP patient {patient}\")\n",
    "    patient_el_ids = np.where(hup_idx_map_arr == patient)[0]\n",
    "    # print(f\"Found {len(patient_el_ids)} electrodes\")\n",
    "    \n",
    "    for idx in patient_el_ids:\n",
    "        # print(f\"Processing electrode {idx}\")\n",
    "        hup_electrode_data = hup_ts.iloc[:, idx].values\n",
    "        # print(f\"Electrode data shape: {hup_electrode_data.shape}\")\n",
    "        hup_iEEGnormal = get_norm_psd(hup_iEEGnormal, hup_electrode_data)\n",
    "        # print(f\"Processed electrode {idx}, DataFrame now has {len(hup_iEEGnormal)} rows\")\n",
    "\n",
    "# print(\"\\nFinished HUP processing, starting MNI\\n\")\n",
    "\n",
    "# For each electrode, we get one scalar value per frequency band for the entire duration of the signal\n",
    "for patient in mni_patient_ids:\n",
    "    # print(f\"Processing MNI patient {patient}\")\n",
    "    patient_el_ids = np.where(mni_idx_map_arr == patient)[0]\n",
    "    # print(f\"Found {len(patient_el_ids)} electrodes\")\n",
    "    \n",
    "    for idx in patient_el_ids:\n",
    "        # print(f\"Processing electrode {idx}\")\n",
    "        mni_electrode_data = mni_ts.iloc[:, idx].values\n",
    "        # print(f\"Electrode data shape: {mni_electrode_data.shape}\")\n",
    "        mni_iEEGnormal = get_norm_psd(mni_iEEGnormal, mni_electrode_data)\n",
    "        # print(f\"Processed electrode {idx}, DataFrame now has {len(mni_iEEGnormal)} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HUP DataFrame shape: (3431, 7)\n",
      "MNI DataFrame shape: (1765, 7)\n",
      "\n",
      "Number of patients processed:\n",
      "HUP patients: 60\n",
      "MNI patients: 106\n",
      "\n",
      "Total electrode counts:\n",
      "HUP electrodes in original data: 3431\n",
      "HUP electrodes processed: 3431\n",
      "MNI electrodes in original data: 1765\n",
      "MNI electrodes processed: 1765\n",
      "\n",
      "Spectral features computed:\n",
      "['deltaRel', 'thetaRel', 'alphaRel', 'betaRel', 'gammaRel', 'broadRel', 'broadlog']\n",
      "\n",
      "First few rows of HUP data:\n",
      "   deltaRel  thetaRel  alphaRel   betaRel  gammaRel  broadRel  broadlog\n",
      "0  0.177924  0.147311  0.135588  0.173211  0.139114  0.226852  2.281969\n",
      "1  0.210691  0.231001  0.098005  0.129331  0.048090  0.282882  1.720748\n",
      "2  0.248122  0.184206  0.116251  0.126453  0.059346  0.265622  2.333526\n",
      "3  0.214907  0.162279  0.114287  0.135578  0.073299  0.299651  1.216269\n",
      "4  0.187794  0.182233  0.136686  0.152295  0.069230  0.271761  1.517257\n"
     ]
    }
   ],
   "source": [
    "# Check dimensions of both DataFrames\n",
    "print(\"HUP DataFrame shape:\", hup_iEEGnormal.shape)\n",
    "print(\"MNI DataFrame shape:\", mni_iEEGnormal.shape)\n",
    "\n",
    "# Check the number of unique patients that were processed\n",
    "print(\"\\nNumber of patients processed:\")\n",
    "print(\"HUP patients:\", len(hup_patient_ids))\n",
    "print(\"MNI patients:\", len(mni_patient_ids))\n",
    "\n",
    "# Verify total electrode counts\n",
    "print(\"\\nTotal electrode counts:\")\n",
    "print(\"HUP electrodes in original data:\", hup_ts.shape[1])  # From (12000, 3431)\n",
    "print(\"HUP electrodes processed:\", len(hup_iEEGnormal))\n",
    "print(\"MNI electrodes in original data:\", mni_ts.shape[1])  # From (13600, 1765)\n",
    "print(\"MNI electrodes processed:\", len(mni_iEEGnormal))\n",
    "\n",
    "# Check what columns we got (spectral features)\n",
    "print(\"\\nSpectral features computed:\")\n",
    "print(hup_iEEGnormal.columns.tolist())\n",
    "\n",
    "# Let's look at the first few rows of data to verify values are reasonable\n",
    "print(\"\\nFirst few rows of HUP data:\")\n",
    "print(hup_iEEGnormal.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['__header__', '__version__', '__globals__', 'None', '__function_workspace__'])\n",
      "<class 'scipy.io.matlab._mio5_params.MatlabOpaque'>\n",
      "(1,)\n",
      "('s0', 's1', 's2', 'arr')\n"
     ]
    }
   ],
   "source": [
    "import scipy.io\n",
    "import pandas as pd\n",
    "\n",
    "mat_file_path = os.path.join(base_path_data, 'metaData.mat')\n",
    "mat_file = sio.loadmat(mat_file_path)\n",
    "\n",
    "# Print all the keys in the loaded .mat file\n",
    "print(mat_file.keys())\n",
    "\n",
    "# Print the type and possibly the shape of the data under 'None'\n",
    "print(type(mat_file['None']))\n",
    "try:\n",
    "    print(mat_file['None'].shape)\n",
    "except AttributeError:\n",
    "    pass  # In case it's not a numpy array\n",
    "\n",
    "# If it's an ndarray and seems to hold structured data, inspect further:\n",
    "if isinstance(mat_file['None'], np.ndarray):\n",
    "    print(mat_file['None'].dtype.names)  # This will print the field names if it's a structured array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0     1     2\n",
      "0 -56.0 -37.0  -2.0\n",
      "1 -60.0 -37.0  -4.0\n",
      "2 -63.0 -37.0  -2.0\n",
      "3 -68.0 -38.0  -2.0\n",
      "4  -1.0  42.0 -14.0\n",
      "(1765, 3)\n"
     ]
    }
   ],
   "source": [
    "mni_chan_pos = pd.DataFrame(mni_atlas['ChannelPosition'])\n",
    "print(mni_chan_pos.head())\n",
    "print(mni_chan_pos.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Line 30 in roiAAL.csv: 29,Insula_L,Subcortical (Insular Cortex),1,3001,-36,7,3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# After reading roiAAL.csv\n",
    "with open(os.path.join(base_path_data, 'roiAAL.csv'), 'r') as file:\n",
    "    lines = file.readlines()\n",
    "    print(f\"Line 30 in roiAAL.csv: {lines[29]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cnt_gen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
