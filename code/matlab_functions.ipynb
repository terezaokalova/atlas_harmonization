{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline:\n",
    "\n",
    "Data Loading and Preprocessing:\n",
    "\n",
    "\n",
    "Loads anatomical atlas data (AAL - Automated Anatomical Labeling)\n",
    "Loads custom ROI (Region of Interest) mappings\n",
    "Loads two cohorts of iEEG data (MNI_atlas and HUP_atlas)\n",
    "Applies parameters for patient selection (Engel score threshold and spike threshold)\n",
    "Feature Extraction\n",
    "\n",
    "Univariate Features:\n",
    "\n",
    "Spectral power in different frequency bands (using Welch's method):\n",
    "Delta (1-4 Hz)\n",
    "Theta (4-8 Hz)\n",
    "Alpha (8-13 Hz)\n",
    "Beta (13-30 Hz)\n",
    "Gamma (30-80 Hz)\n",
    "Broadband (1-80 Hz)\n",
    "Shannon entropy of the signal\n",
    "\n",
    "Multivariate Features:\n",
    "\n",
    "Network connectivity measures\n",
    "Edge-based features\n",
    "Node-based \n",
    "\n",
    "Statistical Analysis:\n",
    "Z-score normalization of features\n",
    "Comparison between cohorts\n",
    "Percentile-based thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sc\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import welch, butter, lfilter\n",
    "from scipy.signal.windows import hamming\n",
    "import nibabel as nib\n",
    "\n",
    "# from scipy.signal import welch, hamming\n",
    "from scipy.stats import zscore\n",
    "from scipy.stats import ttest_ind\n",
    "from pathlib import Path\n",
    "import h5py\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import minmax_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = '/Users/tereza/nishant/atlas/epi_iEEG_atlas'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading MNI atlas...\n",
      "Loading HUP atlas...\n",
      "Loading metadata...\n",
      "Loading custom atlas...\n",
      "Loading roiAAL...\n",
      "\n",
      "Keys in roiAAL: dict_keys(['__header__', '__version__', '__globals__', 'None', '__function_workspace__'])\n",
      "\n",
      "Inspecting key: None\n",
      "Data type and shape: <class 'scipy.io.matlab._mio5_params.MatlabOpaque'> (1,)\n",
      "\n",
      "Successfully created roiAAL DataFrame with shape: (1, 5)\n",
      "\n",
      "Summary of loaded data:\n",
      "MNI_atlas: Dictionary with keys ['__header__', '__version__', '__globals__', 'AgeAtTimeOfStudy', 'ChannelName', 'ChannelPosition', 'ChannelRegion', 'ChannelType', 'Data_N2', 'Data_N3', 'Data_R', 'Data_W', 'FacesLeft', 'FacesRight', 'Gender', 'Hemisphere', 'NodesLeft', 'NodesLeftInflated', 'NodesRegionLeft', 'NodesRegionRight', 'NodesRight', 'NodesRightInflated', 'Patient', 'RegionName', 'SamplingFrequency']\n",
      "HUP_atlas: Dictionary with keys ['__header__', '__version__', '__globals__', 'SamplingFrequency', 'depth_elecs', 'mni_coords', 'patient_no', 'resected_ch', 'soz_ch', 'spike_24h', 'wake_clip']\n",
      "metaData: Dictionary with keys ['__header__', '__version__', '__globals__', 'None', '__function_workspace__']\n",
      "customAAL: DataFrame with shape (40, 5)\n",
      "roiAAL_df: DataFrame with shape (1, 5)\n"
     ]
    }
   ],
   "source": [
    "def load_mat_file(file_path):\n",
    "    \"\"\"\n",
    "    Load .mat file with proper error handling and structure inspection\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # First try loading with scipy.io.loadmat\n",
    "        data = sc.loadmat(file_path)\n",
    "        return data\n",
    "    except NotImplementedError:\n",
    "        # If that fails, try loading as HDF5\n",
    "        try:\n",
    "            with h5py.File(file_path, 'r') as f:\n",
    "                # Convert to dictionary\n",
    "                data = {}\n",
    "                for k, v in f.items():\n",
    "                    data[k] = np.array(v)\n",
    "                return data\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {file_path}: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "def load_and_process_data(base_path):\n",
    "    \"\"\"\n",
    "    Load and process all required data files\n",
    "    \"\"\"\n",
    "    # Define paths\n",
    "    MNI_atlas_path = os.path.join(base_path, 'Data', 'MNI_atlas.mat')\n",
    "    HUP_atlas_path = os.path.join(base_path, 'Data', 'HUP_atlas.mat')\n",
    "    metadata_path = os.path.join(base_path, 'Data', 'metaData.mat')\n",
    "    custom_atlas_path = os.path.join(base_path, 'Data', 'custom_atlas.xlsx')\n",
    "    roiAAL_path = os.path.join(base_path, 'Data', 'roiAAL.mat')\n",
    "    \n",
    "    # Load data files\n",
    "    data = {}\n",
    "    \n",
    "    # Load MNI atlas\n",
    "    print(\"Loading MNI atlas...\")\n",
    "    data['MNI_atlas'] = load_mat_file(MNI_atlas_path)\n",
    "    \n",
    "    # Load HUP atlas\n",
    "    print(\"Loading HUP atlas...\")\n",
    "    data['HUP_atlas'] = load_mat_file(HUP_atlas_path)\n",
    "    \n",
    "    # Load metadata\n",
    "    print(\"Loading metadata...\")\n",
    "    data['metaData'] = load_mat_file(metadata_path)\n",
    "    \n",
    "    # Load custom atlas\n",
    "    print(\"Loading custom atlas...\")\n",
    "    data['customAAL'] = pd.read_excel(custom_atlas_path)\n",
    "    \n",
    "    # Load and process roiAAL\n",
    "    print(\"Loading roiAAL...\")\n",
    "    roiAAL = load_mat_file(roiAAL_path)\n",
    "    \n",
    "    # Print available keys in roiAAL\n",
    "    print(\"\\nKeys in roiAAL:\", roiAAL.keys())\n",
    "    \n",
    "    # Try to extract roiAAL data\n",
    "    roiAAL_data = None\n",
    "    if 'roiAAL' in roiAAL:\n",
    "        roiAAL_data = roiAAL['roiAAL']\n",
    "    else:\n",
    "        # Inspect other keys\n",
    "        for key in roiAAL:\n",
    "            if not key.startswith('__'):\n",
    "                print(f\"\\nInspecting key: {key}\")\n",
    "                print(\"Data type and shape:\", type(roiAAL[key]), np.shape(roiAAL[key]))\n",
    "                roiAAL_data = roiAAL[key]\n",
    "    \n",
    "    # If we found the data, create DataFrame\n",
    "    if roiAAL_data is not None:\n",
    "        try:\n",
    "            data['roiAAL_df'] = pd.DataFrame(roiAAL_data, \n",
    "                                           columns=['Sno', 'parcel', 'Regions', 'Lobes', 'isSideLeft'])\n",
    "            print(\"\\nSuccessfully created roiAAL DataFrame with shape:\", data['roiAAL_df'].shape)\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError creating DataFrame: {str(e)}\")\n",
    "            print(\"roiAAL_data shape:\", np.shape(roiAAL_data))\n",
    "            print(\"roiAAL_data type:\", type(roiAAL_data))\n",
    "            # If it's a structured array, print field names\n",
    "            if hasattr(roiAAL_data, 'dtype') and roiAAL_data.dtype.names is not None:\n",
    "                print(\"Available fields:\", roiAAL_data.dtype.names)\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Test the loading function\n",
    "if __name__ == \"__main__\":\n",
    "    base_path = '/Users/tereza/nishant/atlas/epi_iEEG_atlas'\n",
    "    data = load_and_process_data(base_path)\n",
    "    \n",
    "    # Print summary of loaded data\n",
    "    print(\"\\nSummary of loaded data:\")\n",
    "    for key, value in data.items():\n",
    "        if isinstance(value, pd.DataFrame):\n",
    "            print(f\"{key}: DataFrame with shape {value.shape}\")\n",
    "        elif isinstance(value, dict):\n",
    "            print(f\"{key}: Dictionary with keys {list(value.keys())}\")\n",
    "        else:\n",
    "            print(f\"{key}: {type(value)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Translating MATLAB->Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mergeROIs:\n",
    "- Merges multiple ROIs (Regions of Interest) into custom atlases\n",
    "- Handles parcel assignments and coordinate transformations\n",
    "- Creates a unified atlas for subsequent analysis\n",
    "\n",
    "implant2roi:\n",
    "- Maps electrode coordinates to specific brain regions/ROIs\n",
    "- Performs coordinate system transformations (CRS to RAS)\n",
    "- Creates electrode-to-ROI mapping tables\n",
    "\n",
    "get_norm_psd:\n",
    "- Computes normalized power spectral density for iEEG data\n",
    "- Extracts frequency band powers (delta, theta, alpha, beta, gamma)\n",
    "- Applies noise filtering and normalization\n",
    "\n",
    "get_norm_entropy:\n",
    "- Calculates Shannon entropy of the iEEG signals\n",
    "- Applies bandpass and notch filtering\n",
    "- Adds entropy features to the analysis\n",
    "\n",
    "plot_ieeg_atlas:\n",
    "- Creates visualizations of iEEG data mapped onto brain atlases\n",
    "- Computes regional statistics (mean, std) for different frequency bands\n",
    "- Handles ROI-based data aggregation\n",
    "\n",
    "compare_ieeg_atlas:\n",
    "- Compares metrics between MNI and HUP atlases\n",
    "- Generates comparison plots (electrode counts, bandpower distributions)\n",
    "- Combines and normalizes data from both atlases\n",
    "\n",
    "make_seizure_free/make_seizure_free_abr:\n",
    "- Filters patients based on surgical outcomes (Engel scores)\n",
    "- Identifies healthy vs abnormal tissue regions\n",
    "- Creates subsets for analysis based on clinical criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all custom functions \n",
    "\n",
    "# Python translation of MATLAB's `mergeROIs` function\n",
    "def merge_rois(customAAL, roiAAL, atlas):\n",
    "    \n",
    "    # Convert inputs into appropriate types (assuming customAAL and roiAAL are Pandas DataFrames)\n",
    "    for roi in range(len(customAAL)):\n",
    "        # Assign parcel1 from roiAAL based on customAAL.Roi1\n",
    "        customAAL.loc[roi, 'parcel1'] = roiAAL.loc[customAAL.loc[roi, 'Roi1'], 'parcel']\n",
    "        \n",
    "        # Handle Roi2 assignment\n",
    "        if np.isnan(customAAL.loc[roi, 'Roi2']):\n",
    "            customAAL.loc[roi, 'parcel2'] = np.nan\n",
    "        else:\n",
    "            customAAL.loc[roi, 'parcel2'] = roiAAL.loc[customAAL.loc[roi, 'Roi2'], 'parcel']\n",
    "            atlas['data'][atlas['data'] == customAAL.loc[roi, 'parcel2']] = customAAL.loc[roi, 'parcel1']\n",
    "        \n",
    "        # Handle Roi3 assignment\n",
    "        if np.isnan(customAAL.loc[roi, 'Roi3']):\n",
    "            customAAL.loc[roi, 'parcel3'] = np.nan\n",
    "        else:\n",
    "            customAAL.loc[roi, 'parcel3'] = roiAAL.loc[customAAL.loc[roi, 'Roi3'], 'parcel']\n",
    "            atlas['data'][atlas['data'] == customAAL.loc[roi, 'parcel3']] = customAAL.loc[roi, 'parcel1']\n",
    "    \n",
    "    # Handle inclusion/exclusion logic\n",
    "    included = np.concatenate((customAAL['Roi1'], customAAL['Roi2'], customAAL['Roi3']))\n",
    "    included = included[~np.isnan(included)]  # Remove NaN values\n",
    "    \n",
    "    excluded = np.setxor1d(roiAAL['Sno'], included)\n",
    "    atlas['data'][np.isin(atlas['data'], roiAAL['parcel'][excluded])] = 0\n",
    "\n",
    "    # Create atlasCustom and roiAALcustom as outputs\n",
    "    atlasCustom = atlas\n",
    "    \n",
    "    roiAALcustom = {}\n",
    "    roiAALcustom['Sno'] = np.arange(1, len(customAAL) + 1)\n",
    "    roiAALcustom['Regions'] = customAAL['Roi_name']\n",
    "    roiAALcustom['Lobes'] = customAAL['Lobes']\n",
    "    roiAALcustom['isSideLeft'] = customAAL['Roi_name'].str.endswith('_L')\n",
    "    roiAALcustom['parcel'] = customAAL['parcel1']\n",
    "    \n",
    "    # Calculate coordinates (CRS to RAS transformation)\n",
    "    xyz = []\n",
    "    for roi in range(len(customAAL)):\n",
    "        indices = np.argwhere(atlas['data'] == roiAALcustom['parcel'][roi])\n",
    "        CRS = np.hstack([indices, np.full((indices.shape[0], 1), roiAALcustom['parcel'][roi])])\n",
    "        \n",
    "        RAS = np.dot(atlas['hdr']['Transform']['T'].T, np.hstack([CRS[:, :3], np.ones((CRS.shape[0], 1))]).T).T\n",
    "        RAS = RAS[:, :3]\n",
    "        xyz.append(RAS.mean(axis=0))\n",
    "    xyz = np.array(xyz)\n",
    "    \n",
    "    roiAALcustom['x'] = xyz[:, 0]\n",
    "    roiAALcustom['y'] = xyz[:, 1]\n",
    "    roiAALcustom['z'] = xyz[:, 2]\n",
    "\n",
    "    # Convert roiAALcustom to Pandas DataFrame for easier use\n",
    "    roiAALcustom = pd.DataFrame(roiAALcustom)\n",
    "    \n",
    "    return atlasCustom, roiAALcustom\n",
    "\n",
    "# Python translation of MATLAB's `implant2ROI` function\n",
    "def implant2roi(atlas, electrodeCord, patientNum):\n",
    "\n",
    "    # Get unique ROI from atlas excluding zeros\n",
    "    nROI = np.unique(atlas['data'][atlas['data'] != 0])\n",
    "    \n",
    "    # Get voxel coordinates in CRS format\n",
    "    CRScord = []\n",
    "    for roi in nROI:\n",
    "        indices = np.argwhere(atlas['data'] == roi)\n",
    "        CRS = np.hstack([indices, np.full((indices.shape[0], 1), roi)])\n",
    "        CRScord.append(CRS)\n",
    "    CRScord = np.vstack(CRScord)\n",
    "\n",
    "    # Convert CRS to RAS using atlas transform\n",
    "    RAScord = np.dot(atlas['hdr']['Transform']['T'].T, np.hstack([CRScord[:, :3], np.ones((CRScord.shape[0], 1))]).T).T\n",
    "    RAScord = RAScord[:, :3]\n",
    "    RAScord = np.hstack([RAScord, CRScord[:, 3:]])\n",
    "\n",
    "    # Identify nearest neighbor of each electrode\n",
    "    nbrs = NearestNeighbors(n_neighbors=1, algorithm='auto').fit(RAScord[:, :3])\n",
    "    distances, indices = nbrs.kneighbors(electrodeCord)\n",
    "    atlasROI = RAScord[indices.flatten(), 3]\n",
    "\n",
    "    # Map to ROI numbers\n",
    "    roiNum = [np.where(atlas['tbl']['parcel'] == roi)[0][0] for roi in atlasROI]\n",
    "    \n",
    "    # Create electrode2roi table\n",
    "    electrode2roi = pd.DataFrame({'roiNum': roiNum, 'atlasROI': atlasROI, 'patientNum': patientNum})\n",
    "    \n",
    "    return electrode2roi\n",
    "\n",
    "# Python translation of MATLAB's `getNormPSD` function\n",
    "def get_norm_psd(iEEGnormal, data_timeS, SamplingFrequency):\n",
    "\n",
    "    # Get sampling frequency, time domain data, window length, and NFFT\n",
    "    Fs = SamplingFrequency\n",
    "    data_seg = data_timeS[:Fs*60, :]\n",
    "    window = Fs * 2\n",
    "    NFFT = window\n",
    "\n",
    "    # Compute PSD\n",
    "    f, psd = welch(data_seg, fs=Fs, window=hamming(window), nperseg=window, noverlap=0, nfft=NFFT, axis=0)\n",
    "\n",
    "    # Filter out noise frequency between 57.7Hz and 62.5Hz\n",
    "    idx = (f >= 57.5) & (f <= 62.5)\n",
    "    psd[idx, :] = 0\n",
    "    f = f[~idx]\n",
    "\n",
    "    # Compute bandpower\n",
    "    delta = np.trapz(psd[(f >= 1) & (f < 4)], f[(f >= 1) & (f < 4)], axis=0)\n",
    "    theta = np.trapz(psd[(f >= 4) & (f < 8)], f[(f >= 4) & (f < 8)], axis=0)\n",
    "    alpha = np.trapz(psd[(f >= 8) & (f < 13)], f[(f >= 8) & (f < 13)], axis=0)\n",
    "    beta = np.trapz(psd[(f >= 13) & (f < 30)], f[(f >= 13) & (f < 30)], axis=0)\n",
    "    gamma = np.trapz(psd[(f >= 30) & (f < 80)], f[(f >= 30) & (f < 80)], axis=0)\n",
    "    broad = np.trapz(psd[(f >= 1) & (f < 80)], f[(f >= 1) & (f < 80)], axis=0)\n",
    "\n",
    "    # Log transform\n",
    "    deltalog = np.log10(delta + 1)\n",
    "    thetalog = np.log10(theta + 1)\n",
    "    alphalog = np.log10(alpha + 1)\n",
    "    betalog = np.log10(beta + 1)\n",
    "    gammalog = np.log10(gamma + 1)\n",
    "    broadlog = np.log10(broad + 1)\n",
    "\n",
    "    # Total power\n",
    "    tPow = deltalog + thetalog + alphalog + betalog + gammalog\n",
    "\n",
    "    # Relative power\n",
    "    deltaRel = deltalog / tPow\n",
    "    thetaRel = thetalog / tPow\n",
    "    alphaRel = alphalog / tPow\n",
    "    betaRel = betalog / tPow\n",
    "    gammaRel = gammalog / tPow\n",
    "\n",
    "    # Append to iEEGnormal\n",
    "    iEEGnormal = pd.concat([iEEGnormal, pd.DataFrame({'delta': deltaRel, 'theta': thetaRel, 'alpha': alphaRel, 'beta': betaRel, 'gamma': gammaRel, 'broad': broadlog})], axis=1)\n",
    "\n",
    "    return iEEGnormal\n",
    "\n",
    "# Python translation of MATLAB's `getNormEntropy` function\n",
    "def get_norm_entropy(iEEGnormal, data_timeS, SamplingFrequency):\n",
    "\n",
    "    # Helper functions for filtering\n",
    "    def eeg_filter(data, cutoff, fs, btype, order=3):\n",
    "        nyquist = 0.5 * fs\n",
    "        normal_cutoff = cutoff / nyquist\n",
    "        b, a = butter(order, normal_cutoff, btype=btype, analog=False)\n",
    "        return lfilter(b, a, data, axis=0)\n",
    "\n",
    "    # Get sampling frequency, time domain data, window length, and NFFT\n",
    "    Fs = SamplingFrequency\n",
    "    data_seg = data_timeS[:Fs*60, :]\n",
    "\n",
    "    # Apply filters\n",
    "    data_segbb = eeg_filter(data_seg, 80, Fs, 'low')\n",
    "    data_segbb = eeg_filter(data_segbb, 1, Fs, 'high')\n",
    "    data_segbb_notch = eeg_filter(data_segbb, 60, Fs, 'bandstop')\n",
    "\n",
    "    # Compute Shannon entropy\n",
    "    entropy = np.array([np.log10(-np.sum(p * np.log2(p)) + 1) for p in data_segbb_notch.T])\n",
    "\n",
    "    # Append entropy to iEEGnormal\n",
    "    iEEGnormal = pd.concat([iEEGnormal, pd.DataFrame({'entropy': entropy})], axis=1)\n",
    "\n",
    "    return iEEGnormal\n",
    "\n",
    "\n",
    "# Python translation of MATLAB's `plotiEEGatlas` function\n",
    "def plot_ieeg_atlas(iEEGnormal, atlas, plot_option='noplot'):\n",
    "    \n",
    "    # Create normAtlas dictionary to store data\n",
    "    normAtlas = {}\n",
    "    normAtlas['roi'] = atlas['tbl']['Sno']\n",
    "    normAtlas['name'] = atlas['tbl']['Regions']\n",
    "    normAtlas['lobe'] = atlas['tbl']['Lobes']\n",
    "    normAtlas['isSideLeft'] = atlas['tbl']['isSideLeft']\n",
    "\n",
    "    # Calculate metrics for each ROI\n",
    "    nROIs = len(atlas['tbl']['Sno'])\n",
    "    for roi in range(nROIs):\n",
    "        idx = iEEGnormal['roiNum'] == roi\n",
    "        \n",
    "        # Number of electrodes in each region\n",
    "        normAtlas.setdefault('nElecs', []).append(np.sum(idx))\n",
    "        \n",
    "        # Mean and standard deviation for delta, theta, alpha, beta, gamma, and broad bands\n",
    "        for band in ['delta', 'theta', 'alpha', 'beta', 'gamma', 'broad']:\n",
    "            normAtlas.setdefault(band, []).append(iEEGnormal[band][idx].tolist())\n",
    "            normAtlas.setdefault(f'{band}Mean', []).append(np.mean(iEEGnormal[band][idx]))\n",
    "            normAtlas.setdefault(f'{band}Std', []).append(np.std(iEEGnormal[band][idx]))\n",
    "    \n",
    "    # Convert to DataFrame for easier processing\n",
    "    normAtlas = pd.DataFrame(normAtlas)\n",
    "    \n",
    "    # Remove regions with no electrodes\n",
    "    normAtlas = normAtlas[normAtlas['nElecs'] > 0]\n",
    "\n",
    "    # Plotting logic\n",
    "    if plot_option == 'plot':\n",
    "                \n",
    "        bands = ['deltaMean', 'thetaMean', 'alphaMean', 'betaMean', 'gammaMean', 'broadMean']\n",
    "        for i, band in enumerate(bands):\n",
    "            normAtlas['scaled'] = minmax_scale(normAtlas[band])\n",
    "            nodeVal = pd.DataFrame({\n",
    "                'x': normAtlas['x'],\n",
    "                'y': normAtlas['y'],\n",
    "                'z': normAtlas['z'],\n",
    "                'value': normAtlas['scaled'],\n",
    "                'color': normAtlas['scaled']\n",
    "            })\n",
    "            nodeVal.to_csv('nodeVal.node', sep='\\t', index=False, header=False)\n",
    "            \n",
    "            # Brain network visualization (placeholder for actual implementation)\n",
    "            if i < 5:\n",
    "                # Call some equivalent of BrainNet_MapCfg function for plotting\n",
    "                pass  # Replace with Python visualization library\n",
    "            else:\n",
    "                # Call some equivalent of BrainNet_MapCfg function for plotting (high frequency config)\n",
    "                pass  # Replace with Python visualization library\n",
    "    \n",
    "    return normAtlas\n",
    "\n",
    "# Python translation of MATLAB's `compareiEEGatlas` function\n",
    "def compare_ieeg_atlas(normMNIAtlas, normHUPAtlas, plot_option='noplot'):\n",
    "    \n",
    "    # Filter out matching ROIs\n",
    "    MNI = normMNIAtlas[normMNIAtlas['roi'].isin(normHUPAtlas['roi'])]\n",
    "    HUP = normHUPAtlas[normHUPAtlas['roi'].isin(normMNIAtlas['roi'])]\n",
    "    \n",
    "    if plot_option == 'plot':\n",
    "        # Compare the number of electrodes between atlases\n",
    "        plt.figure()\n",
    "        plt.barh(np.arange(len(MNI)), [MNI['nElecs'], HUP['nElecs']], label=['MNI', 'HUP'])\n",
    "        plt.xlabel('Number of electrodes')\n",
    "        plt.yticks(np.arange(len(MNI)), MNI['name'])\n",
    "        plt.gca().tick_params(axis='y', which='both', labelsize='small')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('Figure/nElec.pdf', format='pdf', dpi=300)\n",
    "\n",
    "        # Get the effect size across regions\n",
    "        plt.figure()\n",
    "        bands = ['deltaMean', 'thetaMean', 'alphaMean', 'betaMean', 'gammaMean', 'broadMean']\n",
    "        data = []\n",
    "        for band in bands:\n",
    "            data.append(np.vstack([MNI[band].values, HUP[band].values]).T)\n",
    "        data = np.concatenate(data, axis=1)\n",
    "        \n",
    "        plt.boxplot(data[:, :10])  # Simplified scatter representation\n",
    "        plt.xticks(np.arange(1, 11), [f'{band}MNI' for band in bands[:5]] + [f'{band}HUP' for band in bands[:5]], rotation=45)\n",
    "        plt.ylabel('Normalized relative bandpower')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('Figure/bandPow.pdf', format='pdf', dpi=300)\n",
    "\n",
    "    # Combine HUP with MNI for missing ROIs\n",
    "    newROIhup = normHUPAtlas[~normHUPAtlas['roi'].isin(normMNIAtlas['roi'])]\n",
    "    normMNIAtlas = pd.concat([normMNIAtlas, newROIhup], ignore_index=True)\n",
    "    \n",
    "    # Update metrics for common ROIs\n",
    "    commonROIhup = normHUPAtlas[normHUPAtlas['roi'].isin(normMNIAtlas['roi'])]\n",
    "    lbl = ['delta', 'theta', 'alpha', 'beta', 'gamma', 'broad']\n",
    "    for _, row in commonROIhup.iterrows():\n",
    "        id = normMNIAtlas.index[normMNIAtlas['roi'] == row['roi']][0]\n",
    "        normMNIAtlas.at[id, 'nElecs'] += row['nElecs']\n",
    "        for band in lbl:\n",
    "            combined = normMNIAtlas.at[id, band] + row[band]\n",
    "            normMNIAtlas.at[id, band] = combined\n",
    "            normMNIAtlas.at[id, f'{band}Mean'] = np.mean(combined)\n",
    "            normMNIAtlas.at[id, f'{band}Std'] = np.std(combined)\n",
    "    \n",
    "    normMNIAtlas = normMNIAtlas.sort_values(by='roi').reset_index(drop=True)\n",
    "    \n",
    "    return normMNIAtlas\n",
    "\n",
    "def node_abr_edge(abr_conn, ieeg_hup_all, percentile_thres):\n",
    "    fbands = [col for col in abr_conn.columns if col.endswith('_z')]\n",
    "    ieeg_abr = []\n",
    "    \n",
    "    for s in range(len(abr_conn)):\n",
    "        node_abr = []\n",
    "        for f in fbands:\n",
    "            adj = abr_conn.loc[s, f]\n",
    "            node_abr.append(np.percentile(adj, percentile_thres, axis=1))\n",
    "        ieeg_abr.append(np.column_stack(node_abr))\n",
    "    \n",
    "    ieeg_abr = np.vstack(ieeg_abr)\n",
    "    ieeg_hup_all = pd.concat([ieeg_hup_all, pd.DataFrame(ieeg_abr, columns=[f + '_coh' for f in fbands])], axis=1)\n",
    "    \n",
    "    return ieeg_hup_all\n",
    "\n",
    "def edgeslist_to_abr_conn(pat_connection, hup_atlas_all):\n",
    "    n_sub = pat_connection['patientNum'].unique()\n",
    "    fbands = [col for col in pat_connection.columns if col.endswith('_z')]\n",
    "    abr_conn = {'patientNum': []}\n",
    "\n",
    "    for s in n_sub:\n",
    "        abr_conn['patientNum'].append(s)\n",
    "        n_elec = (hup_atlas_all['patient_no'] == s).sum()\n",
    "        for f in fbands:\n",
    "            edges = pat_connection.loc[pat_connection['patientNum'] == s, f].values\n",
    "            adj = np.reshape(edges, (n_elec, n_elec))\n",
    "            adj[np.isnan(adj)] = 0\n",
    "            abr_conn.setdefault(f, []).append(np.abs(adj))\n",
    "    \n",
    "    return pd.DataFrame(abr_conn)\n",
    "\n",
    "def univariate_abr(norm_mni_hup_atlas, ieeg_hup_all):\n",
    "    rel_pow_z = []\n",
    "\n",
    "    for n_elec in range(len(ieeg_hup_all)):\n",
    "        roi_num = ieeg_hup_all.loc[n_elec, 'roiNum']\n",
    "        norm_mu = norm_mni_hup_atlas.loc[roi_num, ['deltaMean', 'thetaMean', 'alphaMean', 'betaMean', 'gammaMean', 'broadMean']].values\n",
    "        norm_sigma = norm_mni_hup_atlas.loc[roi_num, ['deltaStd', 'thetaStd', 'alphaStd', 'betaStd', 'gammaStd', 'broadStd']].values\n",
    "        rel_pow = ieeg_hup_all.loc[n_elec, ['delta', 'theta', 'alpha', 'beta', 'gamma', 'broad']].values\n",
    "        rel_pow_z.append(np.abs((rel_pow - norm_mu) / norm_sigma))\n",
    "\n",
    "    rel_pow_z = np.array(rel_pow_z)\n",
    "    ieeg_hup_all_z = pd.concat([ieeg_hup_all.iloc[:, :3], pd.DataFrame(rel_pow_z, columns=['delta_z', 'theta_z', 'alpha_z', 'beta_z', 'gamma_z', 'broad_z'])], axis=1)\n",
    "    \n",
    "    return ieeg_hup_all_z\n",
    "\n",
    "def make_seizure_free_abr(hup_atlas_all, meta_data, engel_sf_thres, spike_thresh):\n",
    "    outcomes = np.nanmax(meta_data[['Engel_6_mo', 'Engel_12_mo']].values, axis=1)\n",
    "    sf_patients = np.where(outcomes <= engel_sf_thres)[0]\n",
    "\n",
    "    sf_patients_ieeg = hup_atlas_all['patient_no'].isin(sf_patients)\n",
    "    resected_sf_ieeg = sf_patients_ieeg & hup_atlas_all['resected_ch']\n",
    "    soz_spared_sf_ieeg = resected_sf_ieeg & hup_atlas_all['soz_ch']\n",
    "    abnormal_ieeg = soz_spared_sf_ieeg & (hup_atlas_all['spike_24h'] > spike_thresh)\n",
    "\n",
    "    hup_abr_atlas = hup_atlas_all.loc[abnormal_ieeg].copy()\n",
    "    hup_abr_atlas['SamplingFrequency'] = hup_atlas_all['SamplingFrequency']\n",
    "    \n",
    "    return hup_abr_atlas\n",
    "\n",
    "def make_seizure_free(hup_atlas_all, meta_data, engel_sf_thres, spike_thresh):\n",
    "    outcomes = np.nanmax(meta_data[['Engel_6_mo', 'Engel_12_mo']].values, axis=1)\n",
    "    sf_patients = np.where(outcomes <= engel_sf_thres)[0]\n",
    "\n",
    "    sf_patients_ieeg = hup_atlas_all['patient_no'].isin(sf_patients)\n",
    "    spared_sf_ieeg = sf_patients_ieeg & ~hup_atlas_all['resected_ch']\n",
    "    not_soz_spared_sf_ieeg = spared_sf_ieeg & ~hup_atlas_all['soz_ch']\n",
    "    healthy_ieeg = not_soz_spared_sf_ieeg & (hup_atlas_all['spike_24h'] < spike_thresh)\n",
    "\n",
    "    hup_atlas = hup_atlas_all.loc[healthy_ieeg].copy()\n",
    "    hup_atlas['SamplingFrequency'] = hup_atlas_all['SamplingFrequency']\n",
    "    \n",
    "    return hup_atlas\n",
    "\n",
    "# Python translation of MATLAB's `mainUnivar` function\n",
    "def main_univar(metaData, atlas, MNI_atlas, HUP_atlasAll, EngelSFThres, spikeThresh):\n",
    "    \n",
    "    # MNI atlas electrode to ROI\n",
    "    electrodeCord = MNI_atlas['ChannelPosition']\n",
    "    patientNum = MNI_atlas['Patient']\n",
    "    iEEG_mni = implant2roi(atlas, electrodeCord, patientNum)\n",
    "\n",
    "    # MNI atlas normalised bandpower\n",
    "    data_MNI = MNI_atlas['Data_W']\n",
    "    SamplingFrequency = MNI_atlas['SamplingFrequency']\n",
    "    iEEG_mni = get_norm_psd(iEEG_mni, data_MNI, SamplingFrequency)\n",
    "\n",
    "    # Seizure-free HUP atlas electrode to ROI\n",
    "    HUP_atlas = make_seizure_free(HUP_atlasAll, metaData, EngelSFThres, spikeThresh)\n",
    "    electrodeCord = HUP_atlas['mni_coords']\n",
    "    patientNum = HUP_atlas['patient_no']\n",
    "    iEEG_hup = implant2roi(atlas, electrodeCord, patientNum)\n",
    "\n",
    "    # HUP atlas normalised bandpower\n",
    "    data_HUP = HUP_atlas['wake_clip']\n",
    "    SamplingFrequency = HUP_atlas['SamplingFrequency']\n",
    "    iEEG_hup = get_norm_entropy(iEEG_hup, data_HUP, SamplingFrequency)\n",
    "\n",
    "    # Visualise MNI and HUP atlas\n",
    "    norm_mni_atlas = plot_ieeg_atlas(iEEG_mni, atlas, plot_option='noplot')\n",
    "    norm_hup_atlas = plot_ieeg_atlas(iEEG_hup, atlas, plot_option='noplot')\n",
    "    norm_MNI_HUP_Atlas = compare_ieeg_atlas(norm_mni_atlas, norm_hup_atlas, plot_option='plot')\n",
    "\n",
    "    # Seizure-free HUP atlas electrode to ROI for all patients\n",
    "    electrodeCord = HUP_atlasAll['mni_coords']\n",
    "    patientNum = HUP_atlasAll['patient_no']\n",
    "    iEEG_hup_all = implant2roi(atlas, electrodeCord, patientNum)\n",
    "    data_HUP_all = HUP_atlasAll['wake_clip']\n",
    "    SamplingFrequency = HUP_atlasAll['SamplingFrequency']\n",
    "    iEEG_hup_all = get_norm_psd(iEEG_hup_all, data_HUP_all, SamplingFrequency)\n",
    "\n",
    "    # Abnormal HUP atlas\n",
    "    HUP_abr_atlas = make_seizure_free_abr(HUP_atlasAll, metaData, EngelSFThres, spikeThresh)\n",
    "    electrodeCord = HUP_abr_atlas['mni_coords']\n",
    "    patientNum = HUP_abr_atlas['patient_no']\n",
    "    iEEG_hup_abr = implant2roi(atlas, electrodeCord, patientNum)\n",
    "    data_HUP_abr = HUP_abr_atlas['wake_clip']\n",
    "    SamplingFrequency = HUP_abr_atlas['SamplingFrequency']\n",
    "    iEEG_hup_abr = get_norm_psd(iEEG_hup_abr, data_HUP_abr, SamplingFrequency)\n",
    "    abrnorm_hup_atlas = plot_ieeg_atlas(iEEG_hup_abr, atlas, plot_option='noplot')\n",
    "    abrnorm_hup_atlas = abrnorm_hup_atlas.sort_values(by='nElecs', ascending=False)\n",
    "\n",
    "    # Address reviewer 1 comment\n",
    "    # pGrp, d = rev1_actual_pow(HUP_abr_atlas, iEEG_hup_abr, HUP_atlas, MNI_atlas, iEEG_hup, iEEG_mni)\n",
    "    # d = rev1_surg_outcome(HUP_atlasAll, iEEG_hup_all, metaData)\n",
    "\n",
    "    return norm_MNI_HUP_Atlas, iEEG_hup_all, abrnorm_hup_atlas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading atlas data...\n",
      "Loading other data files...\n",
      "Creating custom atlas...\n",
      "Error during analysis: 'dict' object has no attribute 'loc'\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # Parameters\n",
    "    EngelSFThres = 1.1\n",
    "    spikeThresh = 24\n",
    "\n",
    "    # Load and prepare atlas data\n",
    "    print(\"Loading atlas data...\")\n",
    "    atlas = {}\n",
    "    atlas_path = os.path.join(base_path, 'Data', 'AAL.nii.gz')\n",
    "    atlas['data'] = nib.load(atlas_path).get_fdata()\n",
    "    atlas['data'][atlas['data'] > 9000] = 0\n",
    "    atlas['hdr'] = nib.load(atlas_path).header\n",
    "    \n",
    "    # Load other required data\n",
    "    print(\"Loading other data files...\")\n",
    "    MNI_atlas = sc.loadmat(os.path.join(base_path, 'Data', 'MNI_atlas.mat'))\n",
    "    HUP_atlas = sc.loadmat(os.path.join(base_path, 'Data', 'HUP_atlas.mat'))\n",
    "    metaData = sc.loadmat(os.path.join(base_path, 'Data', 'metaData.mat'))\n",
    "    customAAL = pd.read_excel(os.path.join(base_path, 'Data', 'custom_atlas.xlsx'))\n",
    "    roiAAL = sc.loadmat(os.path.join(base_path, 'Data', 'roiAAL.mat'))\n",
    "\n",
    "    # Create custom atlas\n",
    "    print(\"Creating custom atlas...\")\n",
    "    atlasCustom, roiAALcustom = merge_rois(customAAL, roiAAL, atlas)\n",
    "    atlas['tbl'] = roiAAL\n",
    "    atlasCustom['tbl'] = roiAALcustom\n",
    "    atlas = atlasCustom\n",
    "\n",
    "    # Run univariate analysis\n",
    "    print(\"Running univariate analysis...\")\n",
    "    norm_MNI_HUP_Atlas, iEEG_hup_all, abrnorm_hup_atlas = main_univar(\n",
    "        metaData, atlas, MNI_atlas, HUP_atlas, EngelSFThres, spikeThresh\n",
    "    )\n",
    "\n",
    "    # Generate univariate z-scores\n",
    "    print(\"Computing univariate z-scores...\")\n",
    "    iEEG_hup_all_z = univariate_abr(norm_MNI_HUP_Atlas, iEEG_hup_all)\n",
    "\n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(os.path.join(base_path, 'Figures'), exist_ok=True)\n",
    "\n",
    "    # Generate and save comparison plots\n",
    "    print(\"Generating comparison plots...\")\n",
    "    plot_comparisons(norm_MNI_HUP_Atlas, iEEG_hup_all_z, base_path)\n",
    "\n",
    "    return norm_MNI_HUP_Atlas, iEEG_hup_all_z, abrnorm_hup_atlas\n",
    "\n",
    "def plot_comparisons(norm_MNI_HUP_Atlas, iEEG_hup_all_z, base_path):\n",
    "    \"\"\"Generate comprehensive comparison plots\"\"\"\n",
    "    \n",
    "    # Plot 1: Feature distributions across cohorts\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    bands = ['delta', 'theta', 'alpha', 'beta', 'gamma']\n",
    "    plt.boxplot([iEEG_hup_all_z[f'{band}_z'] for band in bands])\n",
    "    plt.xticks(range(1, len(bands) + 1), bands)\n",
    "    plt.ylabel('Z-scored Power')\n",
    "    plt.title('Distribution of Frequency Band Powers')\n",
    "    plt.savefig(os.path.join(base_path, 'Figures', 'band_powers.pdf'))\n",
    "    plt.close()\n",
    "\n",
    "    # Plot 2: ROI comparison\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    roi_means = norm_MNI_HUP_Atlas.groupby('roi')[bands].mean()\n",
    "    roi_means.plot(kind='bar')\n",
    "    plt.title('Mean Band Power by ROI')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(base_path, 'Figures', 'roi_comparison.pdf'))\n",
    "    plt.close()\n",
    "\n",
    "# If running in a notebook, you can run this directly:\n",
    "try:\n",
    "    norm_MNI_HUP_Atlas, iEEG_hup_all_z, abrnorm_hup_atlas = main()\n",
    "    print(\"Analysis completed successfully.\")\n",
    "    print(f\"Results saved in {os.path.join(base_path, 'Figures')}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error during analysis: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading MNI atlas...\n",
      "Loading HUP atlas...\n",
      "Loading metadata...\n",
      "Loading custom atlas...\n",
      "Loading roiAAL...\n",
      "\n",
      "Keys in roiAAL: dict_keys(['__header__', '__version__', '__globals__', 'None', '__function_workspace__'])\n",
      "\n",
      "Inspecting key: None\n",
      "Data type and shape: <class 'scipy.io.matlab._mio5_params.MatlabOpaque'> (1,)\n",
      "\n",
      "Successfully created roiAAL DataFrame with shape: (1, 5)\n",
      "Loading atlas data...\n",
      "Creating custom atlas...\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/cnt_gen/lib/python3.12/site-packages/pandas/core/indexes/range.py:413\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 413\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_range\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[0;31mValueError\u001b[0m: 1 is not in range",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 53\u001b[0m\n\u001b[1;32m     49\u001b[0m     plot_comparisons(norm_MNI_HUP_Atlas, iEEG_hup_all_z, base_path)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m norm_MNI_HUP_Atlas, iEEG_hup_all_z, abrnorm_hup_atlas\n\u001b[0;32m---> 53\u001b[0m norm_MNI_HUP_Atlas, iEEG_hup_all_z, abrnorm_hup_atlas \u001b[38;5;241m=\u001b[39m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[15], line 29\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Create custom atlas\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating custom atlas...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 29\u001b[0m atlasCustom, roiAALcustom \u001b[38;5;241m=\u001b[39m \u001b[43mmerge_rois\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcustomAAL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mroiAAL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43matlas\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m atlas[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtbl\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m roiAAL\n\u001b[1;32m     31\u001b[0m atlasCustom[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtbl\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m roiAALcustom\n",
      "Cell \u001b[0;32mIn[4], line 9\u001b[0m, in \u001b[0;36mmerge_rois\u001b[0;34m(customAAL, roiAAL, atlas)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmerge_rois\u001b[39m(customAAL, roiAAL, atlas):\n\u001b[1;32m      5\u001b[0m     \n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# Convert inputs into appropriate types (assuming customAAL and roiAAL are Pandas DataFrames)\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m roi \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(customAAL)):\n\u001b[1;32m      8\u001b[0m         \u001b[38;5;66;03m# Assign parcel1 from roiAAL based on customAAL.Roi1\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m         customAAL\u001b[38;5;241m.\u001b[39mloc[roi, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparcel1\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mroiAAL\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcustomAAL\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mroi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mRoi1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mparcel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     11\u001b[0m         \u001b[38;5;66;03m# Handle Roi2 assignment\u001b[39;00m\n\u001b[1;32m     12\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39misnan(customAAL\u001b[38;5;241m.\u001b[39mloc[roi, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRoi2\u001b[39m\u001b[38;5;124m'\u001b[39m]):\n",
      "File \u001b[0;32m~/anaconda3/envs/cnt_gen/lib/python3.12/site-packages/pandas/core/indexing.py:1183\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1181\u001b[0m     key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(com\u001b[38;5;241m.\u001b[39mapply_if_callable(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m key)\n\u001b[1;32m   1182\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_scalar_access(key):\n\u001b[0;32m-> 1183\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtakeable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_takeable\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1184\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_tuple(key)\n\u001b[1;32m   1185\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1186\u001b[0m     \u001b[38;5;66;03m# we by definition only have the 0th axis\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/cnt_gen/lib/python3.12/site-packages/pandas/core/frame.py:4221\u001b[0m, in \u001b[0;36mDataFrame._get_value\u001b[0;34m(self, index, col, takeable)\u001b[0m\n\u001b[1;32m   4215\u001b[0m engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39m_engine\n\u001b[1;32m   4217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, MultiIndex):\n\u001b[1;32m   4218\u001b[0m     \u001b[38;5;66;03m# CategoricalIndex: Trying to use the engine fastpath may give incorrect\u001b[39;00m\n\u001b[1;32m   4219\u001b[0m     \u001b[38;5;66;03m#  results if our categories are integers that dont match our codes\u001b[39;00m\n\u001b[1;32m   4220\u001b[0m     \u001b[38;5;66;03m# IntervalIndex: IntervalTree has no get_loc\u001b[39;00m\n\u001b[0;32m-> 4221\u001b[0m     row \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4222\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m series\u001b[38;5;241m.\u001b[39m_values[row]\n\u001b[1;32m   4224\u001b[0m \u001b[38;5;66;03m# For MultiIndex going through engine effectively restricts us to\u001b[39;00m\n\u001b[1;32m   4225\u001b[0m \u001b[38;5;66;03m#  same-length tuples; see test_get_set_value_no_partial_indexing\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/cnt_gen/lib/python3.12/site-packages/pandas/core/indexes/range.py:415\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_range\u001b[38;5;241m.\u001b[39mindex(new_key)\n\u001b[1;32m    414\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m--> 415\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Hashable):\n\u001b[1;32m    417\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 1"
     ]
    }
   ],
   "source": [
    "# new \n",
    "\n",
    "def main():\n",
    "    # Parameters\n",
    "    EngelSFThres = 1.1\n",
    "    spikeThresh = 24\n",
    "    \n",
    "    # Load data using the load_and_process_data function\n",
    "    base_path = '/Users/tereza/nishant/atlas/epi_iEEG_atlas'\n",
    "    loaded_data = load_and_process_data(base_path)\n",
    "    \n",
    "    # Extract the loaded data\n",
    "    MNI_atlas = loaded_data['MNI_atlas']\n",
    "    HUP_atlas = loaded_data['HUP_atlas']\n",
    "    metaData = loaded_data['metaData']\n",
    "    customAAL = loaded_data['customAAL']\n",
    "    roiAAL = loaded_data['roiAAL_df']  # Note: using roiAAL_df instead of raw roiAAL\n",
    "\n",
    "    # Load and prepare atlas data\n",
    "    print(\"Loading atlas data...\")\n",
    "    atlas = {}\n",
    "    atlas_path = os.path.join(base_path, 'Data', 'AAL.nii.gz')\n",
    "    atlas['data'] = nib.load(atlas_path).get_fdata()\n",
    "    atlas['data'][atlas['data'] > 9000] = 0\n",
    "    atlas['hdr'] = nib.load(atlas_path).header\n",
    "\n",
    "    # Create custom atlas\n",
    "    print(\"Creating custom atlas...\")\n",
    "    atlasCustom, roiAALcustom = merge_rois(customAAL, roiAAL, atlas)\n",
    "    atlas['tbl'] = roiAAL\n",
    "    atlasCustom['tbl'] = roiAALcustom\n",
    "    atlas = atlasCustom\n",
    "\n",
    "    # Run univariate analysis\n",
    "    print(\"Running univariate analysis...\")\n",
    "    norm_MNI_HUP_Atlas, iEEG_hup_all, abrnorm_hup_atlas = main_univar(\n",
    "        metaData, atlas, MNI_atlas, HUP_atlas, EngelSFThres, spikeThresh\n",
    "    )\n",
    "\n",
    "    # Generate univariate z-scores\n",
    "    print(\"Computing univariate z-scores...\")\n",
    "    iEEG_hup_all_z = univariate_abr(norm_MNI_HUP_Atlas, iEEG_hup_all)\n",
    "\n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(os.path.join(base_path, 'figures'), exist_ok=True)  # Note: changed Figures to figures\n",
    "\n",
    "    # Generate and save comparison plots\n",
    "    print(\"Generating comparison plots...\")\n",
    "    plot_comparisons(norm_MNI_HUP_Atlas, iEEG_hup_all_z, base_path)\n",
    "\n",
    "    return norm_MNI_HUP_Atlas, iEEG_hup_all_z, abrnorm_hup_atlas\n",
    "\n",
    "norm_MNI_HUP_Atlas, iEEG_hup_all_z, abrnorm_hup_atlas = main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cnt_gen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
