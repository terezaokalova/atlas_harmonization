{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sc\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import welch, butter, lfilter\n",
    "from scipy.signal.windows import hamming\n",
    "import nibabel as nib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys in roiAAL: dict_keys(['__header__', '__version__', '__globals__', 'None', '__function_workspace__'])\n",
      "Inspecting key: None\n",
      "Data type and shape: <class 'scipy.io.matlab._mio5_params.MatlabOpaque'> (1,)\n"
     ]
    }
   ],
   "source": [
    "# Paths to data files\n",
    "base_path = '/Users/tereza/nishant/atlas/epi_iEEG_atlas'\n",
    "MNI_atlas_path = os.path.join(base_path, 'Data', 'MNI_atlas.mat')\n",
    "HUP_atlas_path = os.path.join(base_path, 'Data', 'HUP_atlas.mat')\n",
    "metadata_path = os.path.join(base_path, 'Data', 'metaData.mat')\n",
    "custom_atlas_path = os.path.join(base_path, 'Data', 'custom_atlas.xlsx')\n",
    "roiAAL_path = os.path.join(base_path, 'Data', 'roiAAL.mat')\n",
    "\n",
    "# Load data\n",
    "MNI_atlas = sc.loadmat(MNI_atlas_path)\n",
    "HUP_atlas = sc.loadmat(HUP_atlas_path)\n",
    "metaData = sc.loadmat(metadata_path)\n",
    "customAAL = pd.read_excel(custom_atlas_path)\n",
    "roiAAL = sc.loadmat(roiAAL_path)\n",
    "\n",
    "# Inspect roiAAL keys to see what data is available\n",
    "print(\"Keys in roiAAL:\", roiAAL.keys())\n",
    "\n",
    "# Replace 'roiAAL' with the correct key after inspecting the keys\n",
    "if 'roiAAL' in roiAAL:\n",
    "    roiAAL_data = roiAAL['roiAAL']\n",
    "else:\n",
    "    # If 'roiAAL' is not the right key, inspect other keys and extract the right one\n",
    "    for key in roiAAL:\n",
    "        if not key.startswith('__'):\n",
    "            print(f\"Inspecting key: {key}\")\n",
    "            print(\"Data type and shape:\", type(roiAAL[key]), np.shape(roiAAL[key]))\n",
    "\n",
    "# Example \n",
    "roiAAL_df = pd.DataFrame(roiAAL_data, columns=['Sno', 'parcel', 'Regions', 'Lobes', 'isSideLeft'])\n",
    "\n",
    "# Parameters\n",
    "EngelSFThres = 1.1\n",
    "spikeThresh = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['__header__', '__version__', '__globals__', 'None', '__function_workspace__'])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roiAAL.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Translating MATLAB->Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python translation of MATLAB's `mergeROIs` function\n",
    "def merge_rois(customAAL, roiAAL, atlas):\n",
    "    import numpy as np\n",
    "    \n",
    "    # Convert inputs into appropriate types (assuming customAAL and roiAAL are Pandas DataFrames)\n",
    "    for roi in range(len(customAAL)):\n",
    "        # Assign parcel1 from roiAAL based on customAAL.Roi1\n",
    "        customAAL.loc[roi, 'parcel1'] = roiAAL.loc[customAAL.loc[roi, 'Roi1'], 'parcel']\n",
    "        \n",
    "        # Handle Roi2 assignment\n",
    "        if np.isnan(customAAL.loc[roi, 'Roi2']):\n",
    "            customAAL.loc[roi, 'parcel2'] = np.nan\n",
    "        else:\n",
    "            customAAL.loc[roi, 'parcel2'] = roiAAL.loc[customAAL.loc[roi, 'Roi2'], 'parcel']\n",
    "            atlas['data'][atlas['data'] == customAAL.loc[roi, 'parcel2']] = customAAL.loc[roi, 'parcel1']\n",
    "        \n",
    "        # Handle Roi3 assignment\n",
    "        if np.isnan(customAAL.loc[roi, 'Roi3']):\n",
    "            customAAL.loc[roi, 'parcel3'] = np.nan\n",
    "        else:\n",
    "            customAAL.loc[roi, 'parcel3'] = roiAAL.loc[customAAL.loc[roi, 'Roi3'], 'parcel']\n",
    "            atlas['data'][atlas['data'] == customAAL.loc[roi, 'parcel3']] = customAAL.loc[roi, 'parcel1']\n",
    "    \n",
    "    # Handle inclusion/exclusion logic\n",
    "    included = np.concatenate((customAAL['Roi1'], customAAL['Roi2'], customAAL['Roi3']))\n",
    "    included = included[~np.isnan(included)]  # Remove NaN values\n",
    "    \n",
    "    excluded = np.setxor1d(roiAAL['Sno'], included)\n",
    "    atlas['data'][np.isin(atlas['data'], roiAAL['parcel'][excluded])] = 0\n",
    "\n",
    "    # Create atlasCustom and roiAALcustom as outputs\n",
    "    atlasCustom = atlas\n",
    "    \n",
    "    roiAALcustom = {}\n",
    "    roiAALcustom['Sno'] = np.arange(1, len(customAAL) + 1)\n",
    "    roiAALcustom['Regions'] = customAAL['Roi_name']\n",
    "    roiAALcustom['Lobes'] = customAAL['Lobes']\n",
    "    roiAALcustom['isSideLeft'] = customAAL['Roi_name'].str.endswith('_L')\n",
    "    roiAALcustom['parcel'] = customAAL['parcel1']\n",
    "    \n",
    "    # Calculate coordinates (CRS to RAS transformation)\n",
    "    xyz = []\n",
    "    for roi in range(len(customAAL)):\n",
    "        indices = np.argwhere(atlas['data'] == roiAALcustom['parcel'][roi])\n",
    "        CRS = np.hstack([indices, np.full((indices.shape[0], 1), roiAALcustom['parcel'][roi])])\n",
    "        \n",
    "        RAS = np.dot(atlas['hdr']['Transform']['T'].T, np.hstack([CRS[:, :3], np.ones((CRS.shape[0], 1))]).T).T\n",
    "        RAS = RAS[:, :3]\n",
    "        xyz.append(RAS.mean(axis=0))\n",
    "    xyz = np.array(xyz)\n",
    "    \n",
    "    roiAALcustom['x'] = xyz[:, 0]\n",
    "    roiAALcustom['y'] = xyz[:, 1]\n",
    "    roiAALcustom['z'] = xyz[:, 2]\n",
    "\n",
    "    # Convert roiAALcustom to Pandas DataFrame for easier use\n",
    "    import pandas as pd\n",
    "    roiAALcustom = pd.DataFrame(roiAALcustom)\n",
    "    \n",
    "    return atlasCustom, roiAALcustom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python translation of MATLAB's `implant2ROI` function\n",
    "def implant2roi(atlas, electrodeCord, patientNum):\n",
    "\n",
    "    # Get unique ROI from atlas excluding zeros\n",
    "    nROI = np.unique(atlas['data'][atlas['data'] != 0])\n",
    "    \n",
    "    # Get voxel coordinates in CRS format\n",
    "    CRScord = []\n",
    "    for roi in nROI:\n",
    "        indices = np.argwhere(atlas['data'] == roi)\n",
    "        CRS = np.hstack([indices, np.full((indices.shape[0], 1), roi)])\n",
    "        CRScord.append(CRS)\n",
    "    CRScord = np.vstack(CRScord)\n",
    "\n",
    "    # Convert CRS to RAS using atlas transform\n",
    "    RAScord = np.dot(atlas['hdr']['Transform']['T'].T, np.hstack([CRScord[:, :3], np.ones((CRScord.shape[0], 1))]).T).T\n",
    "    RAScord = RAScord[:, :3]\n",
    "    RAScord = np.hstack([RAScord, CRScord[:, 3:]])\n",
    "\n",
    "    # Identify nearest neighbor of each electrode\n",
    "    from sklearn.neighbors import NearestNeighbors\n",
    "    nbrs = NearestNeighbors(n_neighbors=1, algorithm='auto').fit(RAScord[:, :3])\n",
    "    distances, indices = nbrs.kneighbors(electrodeCord)\n",
    "    atlasROI = RAScord[indices.flatten(), 3]\n",
    "\n",
    "    # Map to ROI numbers\n",
    "    roiNum = [np.where(atlas['tbl']['parcel'] == roi)[0][0] for roi in atlasROI]\n",
    "    \n",
    "    # Create electrode2roi table\n",
    "    electrode2roi = pd.DataFrame({'roiNum': roiNum, 'atlasROI': atlasROI, 'patientNum': patientNum})\n",
    "    \n",
    "    return electrode2roi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python translation of MATLAB's `getNormPSD` function\n",
    "def get_norm_psd(iEEGnormal, data_timeS, SamplingFrequency):\n",
    "\n",
    "    # Get sampling frequency, time domain data, window length, and NFFT\n",
    "    Fs = SamplingFrequency\n",
    "    data_seg = data_timeS[:Fs*60, :]\n",
    "    window = Fs * 2\n",
    "    NFFT = window\n",
    "\n",
    "    # Compute PSD\n",
    "    f, psd = welch(data_seg, fs=Fs, window=hamming(window), nperseg=window, noverlap=0, nfft=NFFT, axis=0)\n",
    "\n",
    "    # Filter out noise frequency between 57.7Hz and 62.5Hz\n",
    "    idx = (f >= 57.5) & (f <= 62.5)\n",
    "    psd[idx, :] = 0\n",
    "    f = f[~idx]\n",
    "\n",
    "    # Compute bandpower\n",
    "    delta = np.trapz(psd[(f >= 1) & (f < 4)], f[(f >= 1) & (f < 4)], axis=0)\n",
    "    theta = np.trapz(psd[(f >= 4) & (f < 8)], f[(f >= 4) & (f < 8)], axis=0)\n",
    "    alpha = np.trapz(psd[(f >= 8) & (f < 13)], f[(f >= 8) & (f < 13)], axis=0)\n",
    "    beta = np.trapz(psd[(f >= 13) & (f < 30)], f[(f >= 13) & (f < 30)], axis=0)\n",
    "    gamma = np.trapz(psd[(f >= 30) & (f < 80)], f[(f >= 30) & (f < 80)], axis=0)\n",
    "    broad = np.trapz(psd[(f >= 1) & (f < 80)], f[(f >= 1) & (f < 80)], axis=0)\n",
    "\n",
    "    # Log transform\n",
    "    deltalog = np.log10(delta + 1)\n",
    "    thetalog = np.log10(theta + 1)\n",
    "    alphalog = np.log10(alpha + 1)\n",
    "    betalog = np.log10(beta + 1)\n",
    "    gammalog = np.log10(gamma + 1)\n",
    "    broadlog = np.log10(broad + 1)\n",
    "\n",
    "    # Total power\n",
    "    tPow = deltalog + thetalog + alphalog + betalog + gammalog\n",
    "\n",
    "    # Relative power\n",
    "    deltaRel = deltalog / tPow\n",
    "    thetaRel = thetalog / tPow\n",
    "    alphaRel = alphalog / tPow\n",
    "    betaRel = betalog / tPow\n",
    "    gammaRel = gammalog / tPow\n",
    "\n",
    "    # Append to iEEGnormal\n",
    "    iEEGnormal = pd.concat([iEEGnormal, pd.DataFrame({'delta': deltaRel, 'theta': thetaRel, 'alpha': alphaRel, 'beta': betaRel, 'gamma': gammaRel, 'broad': broadlog})], axis=1)\n",
    "\n",
    "    return iEEGnormal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python translation of MATLAB's `getNormEntropy` function\n",
    "def get_norm_entropy(iEEGnormal, data_timeS, SamplingFrequency):\n",
    "\n",
    "    # Helper functions for filtering\n",
    "    def eeg_filter(data, cutoff, fs, btype, order=3):\n",
    "        nyquist = 0.5 * fs\n",
    "        normal_cutoff = cutoff / nyquist\n",
    "        b, a = butter(order, normal_cutoff, btype=btype, analog=False)\n",
    "        return lfilter(b, a, data, axis=0)\n",
    "\n",
    "    # Get sampling frequency, time domain data, window length, and NFFT\n",
    "    Fs = SamplingFrequency\n",
    "    data_seg = data_timeS[:Fs*60, :]\n",
    "\n",
    "    # Apply filters\n",
    "    data_segbb = eeg_filter(data_seg, 80, Fs, 'low')\n",
    "    data_segbb = eeg_filter(data_segbb, 1, Fs, 'high')\n",
    "    data_segbb_notch = eeg_filter(data_segbb, 60, Fs, 'bandstop')\n",
    "\n",
    "    # Compute Shannon entropy\n",
    "    entropy = np.array([np.log10(-np.sum(p * np.log2(p)) + 1) for p in data_segbb_notch.T])\n",
    "\n",
    "    # Append entropy to iEEGnormal\n",
    "    iEEGnormal = pd.concat([iEEGnormal, pd.DataFrame({'entropy': entropy})], axis=1)\n",
    "\n",
    "    return iEEGnormal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python translation of MATLAB's `plotiEEGatlas` function\n",
    "def plot_ieeg_atlas(iEEGnormal, atlas, plot_option='noplot'):\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    \n",
    "    # Create normAtlas dictionary to store data\n",
    "    normAtlas = {}\n",
    "    normAtlas['roi'] = atlas['tbl']['Sno']\n",
    "    normAtlas['name'] = atlas['tbl']['Regions']\n",
    "    normAtlas['lobe'] = atlas['tbl']['Lobes']\n",
    "    normAtlas['isSideLeft'] = atlas['tbl']['isSideLeft']\n",
    "\n",
    "    # Calculate metrics for each ROI\n",
    "    nROIs = len(atlas['tbl']['Sno'])\n",
    "    for roi in range(nROIs):\n",
    "        idx = iEEGnormal['roiNum'] == roi\n",
    "        \n",
    "        # Number of electrodes in each region\n",
    "        normAtlas.setdefault('nElecs', []).append(np.sum(idx))\n",
    "        \n",
    "        # Mean and standard deviation for delta, theta, alpha, beta, gamma, and broad bands\n",
    "        for band in ['delta', 'theta', 'alpha', 'beta', 'gamma', 'broad']:\n",
    "            normAtlas.setdefault(band, []).append(iEEGnormal[band][idx].tolist())\n",
    "            normAtlas.setdefault(f'{band}Mean', []).append(np.mean(iEEGnormal[band][idx]))\n",
    "            normAtlas.setdefault(f'{band}Std', []).append(np.std(iEEGnormal[band][idx]))\n",
    "    \n",
    "    # Convert to DataFrame for easier processing\n",
    "    normAtlas = pd.DataFrame(normAtlas)\n",
    "    \n",
    "    # Remove regions with no electrodes\n",
    "    normAtlas = normAtlas[normAtlas['nElecs'] > 0]\n",
    "\n",
    "    # Plotting logic\n",
    "    if plot_option == 'plot':\n",
    "        import matplotlib.pyplot as plt\n",
    "        from sklearn.preprocessing import minmax_scale\n",
    "        \n",
    "        bands = ['deltaMean', 'thetaMean', 'alphaMean', 'betaMean', 'gammaMean', 'broadMean']\n",
    "        for i, band in enumerate(bands):\n",
    "            normAtlas['scaled'] = minmax_scale(normAtlas[band])\n",
    "            nodeVal = pd.DataFrame({\n",
    "                'x': normAtlas['x'],\n",
    "                'y': normAtlas['y'],\n",
    "                'z': normAtlas['z'],\n",
    "                'value': normAtlas['scaled'],\n",
    "                'color': normAtlas['scaled']\n",
    "            })\n",
    "            nodeVal.to_csv('nodeVal.node', sep='\\t', index=False, header=False)\n",
    "            \n",
    "            # Brain network visualization (placeholder for actual implementation)\n",
    "            if i < 5:\n",
    "                # Call some equivalent of BrainNet_MapCfg function for plotting\n",
    "                pass  # Replace with Python visualization library\n",
    "            else:\n",
    "                # Call some equivalent of BrainNet_MapCfg function for plotting (high frequency config)\n",
    "                pass  # Replace with Python visualization library\n",
    "    \n",
    "    return normAtlas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python translation of MATLAB's `compareiEEGatlas` function\n",
    "def compare_ieeg_atlas(normMNIAtlas, normHUPAtlas, plot_option='noplot'):\n",
    "    \n",
    "    # Filter out matching ROIs\n",
    "    MNI = normMNIAtlas[normMNIAtlas['roi'].isin(normHUPAtlas['roi'])]\n",
    "    HUP = normHUPAtlas[normHUPAtlas['roi'].isin(normMNIAtlas['roi'])]\n",
    "    \n",
    "    if plot_option == 'plot':\n",
    "        # Compare the number of electrodes between atlases\n",
    "        plt.figure()\n",
    "        plt.barh(np.arange(len(MNI)), [MNI['nElecs'], HUP['nElecs']], label=['MNI', 'HUP'])\n",
    "        plt.xlabel('Number of electrodes')\n",
    "        plt.yticks(np.arange(len(MNI)), MNI['name'])\n",
    "        plt.gca().tick_params(axis='y', which='both', labelsize='small')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('Figure/nElec.pdf', format='pdf', dpi=300)\n",
    "\n",
    "        # Get the effect size across regions\n",
    "        plt.figure()\n",
    "        bands = ['deltaMean', 'thetaMean', 'alphaMean', 'betaMean', 'gammaMean', 'broadMean']\n",
    "        data = []\n",
    "        for band in bands:\n",
    "            data.append(np.vstack([MNI[band].values, HUP[band].values]).T)\n",
    "        data = np.concatenate(data, axis=1)\n",
    "        \n",
    "        plt.boxplot(data[:, :10])  # Simplified scatter representation\n",
    "        plt.xticks(np.arange(1, 11), [f'{band}MNI' for band in bands[:5]] + [f'{band}HUP' for band in bands[:5]], rotation=45)\n",
    "        plt.ylabel('Normalized relative bandpower')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('Figure/bandPow.pdf', format='pdf', dpi=300)\n",
    "\n",
    "    # Combine HUP with MNI for missing ROIs\n",
    "    newROIhup = normHUPAtlas[~normHUPAtlas['roi'].isin(normMNIAtlas['roi'])]\n",
    "    normMNIAtlas = pd.concat([normMNIAtlas, newROIhup], ignore_index=True)\n",
    "    \n",
    "    # Update metrics for common ROIs\n",
    "    commonROIhup = normHUPAtlas[normHUPAtlas['roi'].isin(normMNIAtlas['roi'])]\n",
    "    lbl = ['delta', 'theta', 'alpha', 'beta', 'gamma', 'broad']\n",
    "    for _, row in commonROIhup.iterrows():\n",
    "        id = normMNIAtlas.index[normMNIAtlas['roi'] == row['roi']][0]\n",
    "        normMNIAtlas.at[id, 'nElecs'] += row['nElecs']\n",
    "        for band in lbl:\n",
    "            combined = normMNIAtlas.at[id, band] + row[band]\n",
    "            normMNIAtlas.at[id, band] = combined\n",
    "            normMNIAtlas.at[id, f'{band}Mean'] = np.mean(combined)\n",
    "            normMNIAtlas.at[id, f'{band}Std'] = np.std(combined)\n",
    "    \n",
    "    normMNIAtlas = normMNIAtlas.sort_values(by='roi').reset_index(drop=True)\n",
    "    \n",
    "    return normMNIAtlas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def node_abr_edge(abr_conn, ieeg_hup_all, percentile_thres):\n",
    "    fbands = [col for col in abr_conn.columns if col.endswith('_z')]\n",
    "    ieeg_abr = []\n",
    "    \n",
    "    for s in range(len(abr_conn)):\n",
    "        node_abr = []\n",
    "        for f in fbands:\n",
    "            adj = abr_conn.loc[s, f]\n",
    "            node_abr.append(np.percentile(adj, percentile_thres, axis=1))\n",
    "        ieeg_abr.append(np.column_stack(node_abr))\n",
    "    \n",
    "    ieeg_abr = np.vstack(ieeg_abr)\n",
    "    ieeg_hup_all = pd.concat([ieeg_hup_all, pd.DataFrame(ieeg_abr, columns=[f + '_coh' for f in fbands])], axis=1)\n",
    "    \n",
    "    return ieeg_hup_all\n",
    "\n",
    "def edgeslist_to_abr_conn(pat_connection, hup_atlas_all):\n",
    "    n_sub = pat_connection['patientNum'].unique()\n",
    "    fbands = [col for col in pat_connection.columns if col.endswith('_z')]\n",
    "    abr_conn = {'patientNum': []}\n",
    "\n",
    "    for s in n_sub:\n",
    "        abr_conn['patientNum'].append(s)\n",
    "        n_elec = (hup_atlas_all['patient_no'] == s).sum()\n",
    "        for f in fbands:\n",
    "            edges = pat_connection.loc[pat_connection['patientNum'] == s, f].values\n",
    "            adj = np.reshape(edges, (n_elec, n_elec))\n",
    "            adj[np.isnan(adj)] = 0\n",
    "            abr_conn.setdefault(f, []).append(np.abs(adj))\n",
    "    \n",
    "    return pd.DataFrame(abr_conn)\n",
    "\n",
    "def univariate_abr(norm_mni_hup_atlas, ieeg_hup_all):\n",
    "    rel_pow_z = []\n",
    "\n",
    "    for n_elec in range(len(ieeg_hup_all)):\n",
    "        roi_num = ieeg_hup_all.loc[n_elec, 'roiNum']\n",
    "        norm_mu = norm_mni_hup_atlas.loc[roi_num, ['deltaMean', 'thetaMean', 'alphaMean', 'betaMean', 'gammaMean', 'broadMean']].values\n",
    "        norm_sigma = norm_mni_hup_atlas.loc[roi_num, ['deltaStd', 'thetaStd', 'alphaStd', 'betaStd', 'gammaStd', 'broadStd']].values\n",
    "        rel_pow = ieeg_hup_all.loc[n_elec, ['delta', 'theta', 'alpha', 'beta', 'gamma', 'broad']].values\n",
    "        rel_pow_z.append(np.abs((rel_pow - norm_mu) / norm_sigma))\n",
    "\n",
    "    rel_pow_z = np.array(rel_pow_z)\n",
    "    ieeg_hup_all_z = pd.concat([ieeg_hup_all.iloc[:, :3], pd.DataFrame(rel_pow_z, columns=['delta_z', 'theta_z', 'alpha_z', 'beta_z', 'gamma_z', 'broad_z'])], axis=1)\n",
    "    \n",
    "    return ieeg_hup_all_z\n",
    "\n",
    "def make_seizure_free_abr(hup_atlas_all, meta_data, engel_sf_thres, spike_thresh):\n",
    "    outcomes = np.nanmax(meta_data[['Engel_6_mo', 'Engel_12_mo']].values, axis=1)\n",
    "    sf_patients = np.where(outcomes <= engel_sf_thres)[0]\n",
    "\n",
    "    sf_patients_ieeg = hup_atlas_all['patient_no'].isin(sf_patients)\n",
    "    resected_sf_ieeg = sf_patients_ieeg & hup_atlas_all['resected_ch']\n",
    "    soz_spared_sf_ieeg = resected_sf_ieeg & hup_atlas_all['soz_ch']\n",
    "    abnormal_ieeg = soz_spared_sf_ieeg & (hup_atlas_all['spike_24h'] > spike_thresh)\n",
    "\n",
    "    hup_abr_atlas = hup_atlas_all.loc[abnormal_ieeg].copy()\n",
    "    hup_abr_atlas['SamplingFrequency'] = hup_atlas_all['SamplingFrequency']\n",
    "    \n",
    "    return hup_abr_atlas\n",
    "\n",
    "def make_seizure_free(hup_atlas_all, meta_data, engel_sf_thres, spike_thresh):\n",
    "    outcomes = np.nanmax(meta_data[['Engel_6_mo', 'Engel_12_mo']].values, axis=1)\n",
    "    sf_patients = np.where(outcomes <= engel_sf_thres)[0]\n",
    "\n",
    "    sf_patients_ieeg = hup_atlas_all['patient_no'].isin(sf_patients)\n",
    "    spared_sf_ieeg = sf_patients_ieeg & ~hup_atlas_all['resected_ch']\n",
    "    not_soz_spared_sf_ieeg = spared_sf_ieeg & ~hup_atlas_all['soz_ch']\n",
    "    healthy_ieeg = not_soz_spared_sf_ieeg & (hup_atlas_all['spike_24h'] < spike_thresh)\n",
    "\n",
    "    hup_atlas = hup_atlas_all.loc[healthy_ieeg].copy()\n",
    "    hup_atlas['SamplingFrequency'] = hup_atlas_all['SamplingFrequency']\n",
    "    \n",
    "    return hup_atlas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python translation of MATLAB's `mainUnivar` function\n",
    "def main_univar(metaData, atlas, MNI_atlas, HUP_atlasAll, EngelSFThres, spikeThresh):\n",
    "    \n",
    "    # MNI atlas electrode to ROI\n",
    "    electrodeCord = MNI_atlas['ChannelPosition']\n",
    "    patientNum = MNI_atlas['Patient']\n",
    "    iEEG_mni = implant2roi(atlas, electrodeCord, patientNum)\n",
    "\n",
    "    # MNI atlas normalised bandpower\n",
    "    data_MNI = MNI_atlas['Data_W']\n",
    "    SamplingFrequency = MNI_atlas['SamplingFrequency']\n",
    "    iEEG_mni = get_norm_psd(iEEG_mni, data_MNI, SamplingFrequency)\n",
    "\n",
    "    # Seizure-free HUP atlas electrode to ROI\n",
    "    HUP_atlas = make_seizure_free(HUP_atlasAll, metaData, EngelSFThres, spikeThresh)\n",
    "    electrodeCord = HUP_atlas['mni_coords']\n",
    "    patientNum = HUP_atlas['patient_no']\n",
    "    iEEG_hup = implant2roi(atlas, electrodeCord, patientNum)\n",
    "\n",
    "    # HUP atlas normalised bandpower\n",
    "    data_HUP = HUP_atlas['wake_clip']\n",
    "    SamplingFrequency = HUP_atlas['SamplingFrequency']\n",
    "    iEEG_hup = get_norm_entropy(iEEG_hup, data_HUP, SamplingFrequency)\n",
    "\n",
    "    # Visualise MNI and HUP atlas\n",
    "    norm_mni_atlas = plot_ieeg_atlas(iEEG_mni, atlas, plot_option='noplot')\n",
    "    norm_hup_atlas = plot_ieeg_atlas(iEEG_hup, atlas, plot_option='noplot')\n",
    "    norm_MNI_HUP_Atlas = compare_ieeg_atlas(norm_mni_atlas, norm_hup_atlas, plot_option='plot')\n",
    "\n",
    "    # Seizure-free HUP atlas electrode to ROI for all patients\n",
    "    electrodeCord = HUP_atlasAll['mni_coords']\n",
    "    patientNum = HUP_atlasAll['patient_no']\n",
    "    iEEG_hup_all = implant2roi(atlas, electrodeCord, patientNum)\n",
    "    data_HUP_all = HUP_atlasAll['wake_clip']\n",
    "    SamplingFrequency = HUP_atlasAll['SamplingFrequency']\n",
    "    iEEG_hup_all = get_norm_psd(iEEG_hup_all, data_HUP_all, SamplingFrequency)\n",
    "\n",
    "    # Abnormal HUP atlas\n",
    "    HUP_abr_atlas = make_seizure_free_abr(HUP_atlasAll, metaData, EngelSFThres, spikeThresh)\n",
    "    electrodeCord = HUP_abr_atlas['mni_coords']\n",
    "    patientNum = HUP_abr_atlas['patient_no']\n",
    "    iEEG_hup_abr = implant2roi(atlas, electrodeCord, patientNum)\n",
    "    data_HUP_abr = HUP_abr_atlas['wake_clip']\n",
    "    SamplingFrequency = HUP_abr_atlas['SamplingFrequency']\n",
    "    iEEG_hup_abr = get_norm_psd(iEEG_hup_abr, data_HUP_abr, SamplingFrequency)\n",
    "    abrnorm_hup_atlas = plot_ieeg_atlas(iEEG_hup_abr, atlas, plot_option='noplot')\n",
    "    abrnorm_hup_atlas = abrnorm_hup_atlas.sort_values(by='nElecs', ascending=False)\n",
    "\n",
    "    # Address reviewer 1 comment\n",
    "    # pGrp, d = rev1_actual_pow(HUP_abr_atlas, iEEG_hup_abr, HUP_atlas, MNI_atlas, iEEG_hup, iEEG_mni)\n",
    "    # d = rev1_surg_outcome(HUP_atlasAll, iEEG_hup_all, metaData)\n",
    "\n",
    "    return norm_MNI_HUP_Atlas, iEEG_hup_all, abrnorm_hup_atlas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'AAL'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinished processing. Results are available in the output variables.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 23\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[42], line 6\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmain\u001b[39m():\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# Assuming merge_rois and main_univar are already defined in your script\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m# Merge ROIs\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     atlas \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m----> 6\u001b[0m     atlas[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mMNI_atlas\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mAAL\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m  \u001b[38;5;66;03m# Replace with actual data from MNI_atlas\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     atlas[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhdr\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTransform\u001b[39m\u001b[38;5;124m'\u001b[39m: {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mT\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39meye(\u001b[38;5;241m4\u001b[39m)}}  \u001b[38;5;66;03m# Replace with the actual transformation data\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     atlasCustom, roiAALcustom \u001b[38;5;241m=\u001b[39m merge_rois(customAAL, roiAAL_df, atlas)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'AAL'"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # Assuming merge_rois and main_univar are already defined in your script\n",
    "\n",
    "    # Merge ROIs\n",
    "    atlas = {}\n",
    "    atlas['data'] = MNI_atlas['AAL']  # Replace with actual data from MNI_atlas\n",
    "    atlas['hdr'] = {'Transform': {'T': np.eye(4)}}  # Replace with the actual transformation data\n",
    "\n",
    "    atlasCustom, roiAALcustom = merge_rois(customAAL, roiAAL_df, atlas)\n",
    "\n",
    "    # Run univariate analysis\n",
    "    norm_MNI_HUP_Atlas, iEEG_hup_all, abrnorm_hup_atlas = main_univar(\n",
    "        metaData, atlasCustom, MNI_atlas, HUP_atlas, EngelSFThres, spikeThresh\n",
    "    )\n",
    "\n",
    "    print(\"Finished processing. Results are available in the output variables.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cnt_gen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
